{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'>Model Builder Template</font> \n",
    "## Overview\n",
    "* \t\t\tThis template is used for seamless integration with CDMS serving layer by preparing `custom_model.py` and `metadata.json` files.\n",
    "* \t\t\tWhen this template is opened, a folder with name same as Model Code was created in the local. \n",
    "* \t\t\tThe cells with code containing <i>import statements</i> or <i>function definitions</i> will be extracted to the `custom_model.py`.\n",
    "* \t\t\tPlease refer to the Model Onboarding User Guide to get the detailed working of this template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Rename your notebook file to some meaningful model before doing \t\t\tany model development. Changing notebook name after onboarding can make your code behave erroneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (IPython.notebook.kernel) {IPython.notebook.kernel.execute('nb_name = ' + '\"' + IPython.notebook.notebook_name + '\"')}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Meta data Information\n",
    "* \t\t\tPlease enter a unique model code, model name (e.g. Customer Churn, Propensity to Default, CLTV etc) and Model description.\n",
    "* \t\t\tPlease ensure the 'Create Workspace' button is clicked.\n",
    "* \t\t\tFor more information, please refer to the User Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246330c5c864452fbb4a99a1bcdee41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='MC1', description='Model Code', disabled=True, placeholder=''), Dropâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50312b9cb9d4691a47ee517a41e7a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Create Workspace', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403fbd62bd494363a2ffcf04fd356536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enter_metadata_information(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "* \t\t\tThe following cell can be used to import all the required python packages.\n",
    "* \t\t\tPlease import the `gr` package to use the pre-defined models and functionalities. \t\t\tFor more information, please refer to the User Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#imports \n",
    "import os, sys, pickle;\n",
    "from datetime import datetime\n",
    "from typing import Dict\n",
    "#For address comparision\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "# To suppress SettingWithCopyWarning in the code\n",
    "pd.options.mode.chained_assignment = None\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pointbiserialr, stats\n",
    "from imblearn.over_sampling import SMOTE, ADASYN \n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_curve, \n",
    "    roc_auc_score,precision_recall_curve, f1_score, accuracy_score, auc)\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.feature_selection import RFE, SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.model_selection import (train_test_split,KFold,StratifiedKFold,GridSearchCV,RandomizedSearchCV,cross_val_score,RepeatedKFold)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import traceback\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import gc\n",
    "#model explanability import\n",
    "\n",
    "import gzip\n",
    "\n",
    "import pickle\n",
    "import shap\n",
    "import fsspec\n",
    "from io import StringIO\n",
    "\n",
    "import logging\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_level = logging.INFO\n",
    "if platform.system() == \"Windows\":\n",
    "    log_level = logging.DEBUG\n",
    "logging.basicConfig(\n",
    "        level=log_level,\n",
    "        format=\"[%(asctime)s] %(levelname)s [%(name)s.%(funcName)s:%(lineno)d] %(message)s\",\n",
    "        datefmt='%Y-%m-%dT%H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.StreamHandler(),\n",
    "            logging.FileHandler('./fraud_detection.log')\n",
    "        ]\n",
    "    )\n",
    "logger = logging.getLogger(\"cdms_pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model \n",
    "* \t\t\tThe following method can be used to save the trained model in the model folder structure created. \n",
    "* \t\t\tThe method parameter `trained_model` accepts the estimator(trained model) that is to be stored as model `pickle` file. \n",
    " \t\t\tThe method parameter `filename` accepts a `string` containing the pickle file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(trained_model, file_name):    \n",
    "    model_pickle_path = None\n",
    "    try:\n",
    "        model_pickle_path = os.path.abspath(os.path.join(__file__, os.pardir, file_name))\n",
    "    except Exception:\n",
    "        model_pickle_path = os.path.join(os.path.abspath(''),file_name)\n",
    "    logger.info(f\"Saving to location {model_pickle_path}.\")\n",
    "    with open(model_pickle_path, 'wb') as pickle_out:\n",
    "        pickle.dump(trained_model, pickle_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model \n",
    "* \t\t\tThe following method can be used to load the saved model from the model folder structure. \n",
    "* \t\t\tThe method parameter `filename` accepts a `string` containing the model pickle file name that is to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_name):    \n",
    "    model = None\n",
    "    model_pickle_path = None\n",
    "    try:\n",
    "        model_pickle_path = os.path.abspath(os.path.join(__file__, os.pardir, file_name))\n",
    "    except Exception:\n",
    "        model_pickle_path = os.path.join(os.path.abspath(''),file_name)\n",
    "    logger.info(f\"Loading model from location {model_pickle_path}.\")\n",
    "    with open(model_pickle_path, 'rb') as pickle_in:\n",
    "        model = pickle.load(pickle_in)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_data(df_x, drop_cols_list):\n",
    "    logger.info(\"clean_data\")\n",
    "    present_cols = [col for col in drop_cols_list if col in df_x.columns]\n",
    "    df_x = df_x.drop(present_cols,axis = 1)\n",
    "    return df_x\n",
    "\n",
    "def calculate_age(born):\n",
    "    today = datetime.today() \n",
    "    try:  \n",
    "        birthday = born.replace(year = today.year) \n",
    "\n",
    "    # raised when birth date is February 29 \n",
    "    # and the current year is not a leap year \n",
    "    except ValueError:  \n",
    "        birthday = born.replace(year = today.year, \n",
    "                  month = born.month + 1, day = 1) \n",
    "\n",
    "    if birthday > today: \n",
    "        return today.year - born.year - 1\n",
    "    else: \n",
    "        return today.year - born.year \n",
    "\n",
    "\n",
    "def is_ambigious_workexp(work_exp, age, work_start_age):\n",
    "    if work_exp <= (age*12 - work_start_age):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def match_column(text1,text2,threshold):\n",
    "    match_ratio = fuzz.token_sort_ratio(text1, text2)\n",
    "    if match_ratio >= threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def is_card_expired(exp_date, file_date):\n",
    "    if exp_date is pd.NaT:\n",
    "        return -1\n",
    "    if exp_date < file_date:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def is_banking_fraud(payment_mode, res_mail_address_match):\n",
    "    if payment_mode=='D' and res_mail_address_match==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def invalid_dob(age):\n",
    "    if age < 16 or age>80:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "#Outlier functions\n",
    "def q1_quantile(x):\n",
    "    q25 = x.quantile(0.25)\n",
    "    if (q25 < 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return q25\n",
    "\n",
    "\n",
    "def q2_quantile(x):\n",
    "    q50 = x.quantile(0.50)\n",
    "    if (q50 < 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return q50\n",
    "\n",
    "def q3_quantile(x):\n",
    "    q75 = x.quantile(0.75)\n",
    "    if (q75 < 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return q75\n",
    "\n",
    "def upper_count_limit(q1_quantile, q3_quantile):\n",
    "    iqr_count = q3_quantile - q1_quantile\n",
    "    upper_limit = q3_quantile + (1.5*iqr_count)\n",
    "    return upper_limit\n",
    "\n",
    "def rename_keys(rename_dict, feature_important):\n",
    "    logger.info(\"Rename keys\")\n",
    "    logger.debug(rename_dict)\n",
    "    logger.debug(feature_important)\n",
    "    new_dict = {}\n",
    "    for k , v in feature_important.items():\n",
    "        if rename_dict.get(k):\n",
    "            new_dict[rename_dict.get(k)] = v\n",
    "        else:\n",
    "            new_dict[k] = v\n",
    "    return new_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    def __init__(self, file_system, input_dict, training=True):\n",
    "        logger.info(\"Preprocessing initialization\")\n",
    "\n",
    "        self.fs = file_system\n",
    "        self.input_dict = input_dict\n",
    "        self.input_file_path = input_dict[\"file_path\"]\n",
    "        self.is_train = training\n",
    "        \n",
    "        self.fraud_indicator_cols = ['STATE_ID_THEFT','ID_EXPIRED','IS_ID_MISSING','IS_ID_NOT_LOCAL','IS_ID_STATE_NOT_MATCHING_MAIL',\\\n",
    "                            'IS_ID_STATE_NOT_MATCHING_RES','ACC_NUMBER_THEFT','IS_ACC_MISSING','EMAIL_THEFT','PHONE_THEFT',\\\n",
    "                            'LIVING_TOGETHER','CORRESPONDING_TOGETHER','NOT_SAME_MAIL_RES_ADDR','IS_SKILL_PREFERENCE_NOT_MATCHING',\\\n",
    "                            'IS_MAIL_STATE_NOT_LOCAL','IS_suspicious_DOB','INVALID_DOB','IS_WORK_EXP_AMBIGIOUS','IS_EMPLOYER_MISSING',\\\n",
    "                            'HAS_FRAUD_HISTORY']\n",
    "        self.cols_dtype_dict = {\"CLAIMANT_ID\":str, \"CLAIMANT_ID_x\":str, \"CLAIM_APPLICATION_ID\":str, \"CLAIMANT_ID_y\":str}\n",
    "        self.raw_per_df = self._read_csv_folder(os.path.join(self.input_file_path, self.input_dict[\"raw_per_df\"]), low_memory=False, converters=self.cols_dtype_dict)\n",
    "        self.interim_df = pd.DataFrame()\n",
    "        # Check if folder is present and folder is not empty\n",
    "        interim_df_path = os.path.join(self.input_file_path, self.input_dict[\"interim_df\"])\n",
    "        if self.fs.isdir(interim_df_path) and len(self.fs.ls(interim_df_path))>0:\n",
    "            self.interim_df = self._read_csv_folder(interim_df_path, low_memory=False, converters=self.cols_dtype_dict)\n",
    "        # During training, interim dataframe if present will be concated to raw_per_df.\n",
    "        # During prediction, interim dataframe if present will be concated to raw_per_df_history.\n",
    "        if self.is_train and not self.interim_df.empty:\n",
    "            logger.info(\"Merging claimnat personal details interim data during training.\")\n",
    "            self.raw_per_df = pd.concat([self.raw_per_df, self.interim_df], sort=True).reset_index(drop=True)\n",
    "        skill_df_path = os.path.join(self.input_file_path,  self.input_dict[\"skill_df\"])\n",
    "        self.skill_df = self._read_csv_folder(skill_df_path, low_memory=False, converters=self.cols_dtype_dict)\n",
    "        employment_df_path = os.path.join(self.input_file_path, self.input_dict[\"employment_df\"])\n",
    "        self.employment_df = self._read_csv_folder(employment_df_path, low_memory=False, converters=self.cols_dtype_dict)\n",
    "        employer_df_path = os.path.join(self.input_file_path, self.input_dict[\"employer_df\"])\n",
    "        self.employer_df = self._read_csv_folder(employer_df_path, low_memory=False, converters=self.cols_dtype_dict)\n",
    "        claimant_history_personal_details_path = os.path.join(self.input_file_path, self.input_dict[\"Claimant_History_Personal_Details\"])\n",
    "        self.claimant_history_personal_details = self._read_csv_folder(claimant_history_personal_details_path, low_memory=False, converters=self.cols_dtype_dict)\n",
    "        claimant_history_skill_details_path = os.path.join(self.input_file_path, self.input_dict[\"Claimant_History_Skill_Details\"])\n",
    "        self.claimant_history_skill_details = self._read_csv_folder(claimant_history_skill_details_path, low_memory=False, converters=self.cols_dtype_dict)\n",
    "\n",
    "    def _read_csv_folder(self, input_file_path, glob_pattern=\"*.csv\", **kwrags):\n",
    "        logger.info(f\"Reading csv from folder {input_file_path}\")\n",
    "        df_list = []\n",
    "        if self.fs.isdir(input_file_path):\n",
    "            if len(self.fs.ls(input_file_path))>0:\n",
    "                for fl in self.fs.glob(os.path.join(input_file_path, glob_pattern)):\n",
    "                    if self.fs.du(fl)>0:\n",
    "                        with self.fs.open(fl) as f:\n",
    "                            df = pd.read_csv(f, **kwrags)\n",
    "                            df_list.append(df)\n",
    "            else:\n",
    "                logger.error(f\"No file found in {input_file_path}.\")\n",
    "                raise FileNotFoundError(f\"No file found in {input_file_path}.\")\n",
    "        else:\n",
    "            logger.warning(f\"{input_file_path} is not a directory.\")\n",
    "            raise ValueError(f\"{input_file_path} is not a directory.\")\n",
    "        if df_list:\n",
    "            return pd.concat(df_list, sort=True).reset_index(drop=True)\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def pi_missing_treatment(self):\n",
    "        '''\n",
    "        Special treatment for bank account and routing number\n",
    "        It looks like 04a4c7210f9df2d6a80433450b94d9007c97 value represents the missing value for bank account number and \n",
    "        routing number and state id. This method replaces these values with np.NaN\n",
    "        '''\n",
    "        logger.info(\"pi_missing_treatment\")\n",
    "        missing_val_map = {'04a4c7210f9df2d6a80433450b94d9007c97':np.NaN}\n",
    "        replace_dict = {'CLAIMANT_STATE_ID_NO':missing_val_map, \n",
    "                   'CLAIMANT_BANK_ROUTING_NUMBER':missing_val_map,\n",
    "                   'CLAIMANT_BANK_ACCOUNT_NUMBER':missing_val_map}\n",
    "        self.raw_per_df = self.raw_per_df.replace(to_replace=replace_dict)\n",
    "        \n",
    "        # Remove duplicate and ambigious records, drop unwanted columns and rename column\n",
    "        # Remove row where claimant_id_x and claimant_id_y are not matching. This is already handled in ETL and hence commented in model code.\n",
    "        # Remove unwanted columns\n",
    "        cols_to_drop = ['CLAIMANT_MAILING_ADDRESS_LINE_2','CLAIMANT_RESIDENTIAL_ADDRESS_LINE_2',\\\n",
    "                'CLAIMANT_RESIDENTIAL_COUNTRY','CLAIMANT_MAILING_ADDRESS_COUNTRY','CLAIMANT_EMAIL'\n",
    "                ]\t\t\n",
    "        self.raw_per_df = self.raw_per_df.drop(cols_to_drop, axis=1)\n",
    "        # Rename columns\n",
    "        self.raw_per_df.rename(columns={\"CLAIMANT_ID_x\": \"CLAIMANT_ID\"}, inplace=True)\n",
    "        # Drop duplicates records\n",
    "        self.raw_per_df = self.raw_per_df.drop_duplicates(subset = [\"CLAIMANT_ID\", \"CLAIM_APPLICATION_ID\"])\n",
    "    \n",
    "    def pi_match_feature(self):\n",
    "        '''\n",
    "        Bank account, State ID, Address matching, work and residential ZIP match\n",
    "        '''\n",
    "        logger.info(\"pi_match_feature\")\n",
    "        self.raw_per_df['CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID'] = np.floor(pd.to_numeric(self.raw_per_df['CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID'], errors='coerce'))\n",
    "        self.raw_per_df['CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID'] = self.raw_per_df['CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID'].astype('object')\n",
    "\n",
    "        self.raw_per_df[\"CLAIMANT_STATE_ID_EXPIRATION_DATE\"] = pd.to_datetime(self.raw_per_df[\"CLAIMANT_STATE_ID_EXPIRATION_DATE\"], format=\"%Y-%m-%d\", errors='coerce').dt.date\n",
    "        self.raw_per_df[\"CLAIM_APPLICATION_FILE_DATE\"] = pd.to_datetime(self.raw_per_df[\"CLAIM_APPLICATION_FILE_DATE\"], format=\"%d-%m-%Y\").dt.date\n",
    "        self.raw_per_df[\"CLAIMANT_DATE_OF_BIRTH\"] = pd.to_datetime(self.raw_per_df[\"CLAIMANT_DATE_OF_BIRTH\"], format=\"%d-%m-%Y\").dt.date\n",
    "        #State Id related features\n",
    "        self.raw_per_df['IS_ID_MISSING'] = (~self.raw_per_df[\"CLAIMANT_STATE_ID_ISSUING_STATE\"].notnull()).astype('int')\n",
    "        # The condition checks for notnull based on the concept NaN != NaN  in pandas.\n",
    "        # REFER https://stackoverflow.com/a/46021212/5462372 for condition in query written below. \n",
    "        self.raw_per_df['IS_ID_NOT_LOCAL'] = self.raw_per_df.query(\"CLAIMANT_STATE_ID_ISSUING_STATE == CLAIMANT_STATE_ID_ISSUING_STATE\")[\"CLAIMANT_STATE_ID_ISSUING_STATE\"].ne('MS').astype('int')\n",
    "        self.raw_per_df['IS_ID_STATE_NOT_MATCHING_RES'] = self.raw_per_df.query(\"CLAIMANT_STATE_ID_ISSUING_STATE == CLAIMANT_STATE_ID_ISSUING_STATE\").apply(lambda x: 0 if x.CLAIMANT_STATE_ID_ISSUING_STATE==x.CLAIMANT_RESIDENTIAL_ADDRESS_STATE else 1, axis=1)                                   \n",
    "        self.raw_per_df['IS_ID_STATE_NOT_MATCHING_MAIL'] = self.raw_per_df.query(\"CLAIMANT_STATE_ID_ISSUING_STATE == CLAIMANT_STATE_ID_ISSUING_STATE\").apply(lambda x: 0 if x.CLAIMANT_STATE_ID_ISSUING_STATE==x.CLAIMANT_MAILING_ADDRESS_STATE else 1, axis=1)\n",
    "        self.raw_per_df['ID_EXPIRED'] = self.raw_per_df.query(\"CLAIMANT_STATE_ID_EXPIRATION_DATE == CLAIMANT_STATE_ID_EXPIRATION_DATE\").apply(lambda x: is_card_expired(x.CLAIMANT_STATE_ID_EXPIRATION_DATE, x.CLAIM_APPLICATION_FILE_DATE),axis=1)\n",
    "        \n",
    "        #Claimant address related features\n",
    "        self.raw_per_df['IS_MAIL_STATE_NOT_LOCAL'] = self.raw_per_df[\"CLAIMANT_MAILING_ADDRESS_STATE\"].ne('MS').astype('int')\n",
    "        self.raw_per_df['IS_RES_STATE_NOT_LOCAL'] = self.raw_per_df[\"CLAIMANT_RESIDENTIAL_ADDRESS_STATE\"].ne('MS').astype('int')\n",
    "        logger.debug(f\"raw_per_df shape IS_RES_STATE_NOT_LOCAL {self.raw_per_df.shape}\")\n",
    "        self.raw_per_df['RES_ADDR'] = self.raw_per_df['CLAIMANT_RESIDENTIAL_ADDRESS_LINE_1'].astype(str)+ \\\n",
    "                                    ' ' + self.raw_per_df['CLAIMANT_RESIDENTIAL_ADDRESS_CITY'].astype(str)+ \\\n",
    "                                    ' ' + self.raw_per_df['CLAIMANT_RESIDENTIAL_ADDRESS_STATE'].astype(str)+ \\\n",
    "                                    ' ' + self.raw_per_df['CLAIMANT_RESIDENTIAL_ADDRESS_ZIP'].astype(str)\n",
    "        self.raw_per_df['MAIL_ADDR'] = self.raw_per_df['CLAIMANT_MAILING_ADDRESS_LINE_1'].astype(str)+ \\\n",
    "                                    ' ' + self.raw_per_df['CLAIMANT_MAILING_ADDRESS_CITY'].astype(str)+ \\\n",
    "                                    ' ' + self.raw_per_df['CLAIMANT_MAILING_ADDRESS_STATE'].astype(str)+ \\\n",
    "                                    ' ' + self.raw_per_df['CLAIMANT_MAILING_ADDRESS_ZIP'].astype(str)\n",
    "\n",
    "        temp_df = self.raw_per_df[['CLAIMANT_ID','CLAIM_APPLICATION_ID','RES_ADDR']].drop_duplicates(['CLAIMANT_ID','RES_ADDR'],keep= 'last')\n",
    "        dict_res_address = dict(temp_df.RES_ADDR.value_counts() > 1)\n",
    "        self.raw_per_df['LIVING_TOGETHER'] = self.raw_per_df['RES_ADDR'].map(dict_res_address)\n",
    "\n",
    "        temp_df = self.raw_per_df[['CLAIMANT_ID','CLAIM_APPLICATION_ID','MAIL_ADDR']].drop_duplicates(['CLAIMANT_ID','MAIL_ADDR'],keep= 'last')\n",
    "        dict_mail_address = dict(temp_df.MAIL_ADDR.value_counts() > 1)\n",
    "        self.raw_per_df['CORRESPONDING_TOGETHER'] = self.raw_per_df['MAIL_ADDR'].map(dict_mail_address)\n",
    "        self.raw_per_df['NOT_SAME_MAIL_RES_ADDR'] = self.raw_per_df.apply(lambda x: match_column(x.RES_ADDR,x.MAIL_ADDR,90), axis=1)\n",
    "        self.raw_per_df['NOT_SAME_WORK_PRE_RES_ZIP'] = self.raw_per_df.apply(lambda x: match_column(x.CLAIMANT_RESIDENTIAL_ADDRESS_ZIP,x.CLAIMANT_PREFERRED_WORK_ZIP_CODE,100), axis=1)\n",
    "\n",
    "        #Claimant personal related features\n",
    "        # Get the age\n",
    "        self.raw_per_df[\"CLAIMANT_DATE_OF_BIRTH\"] = pd.to_datetime(self.raw_per_df[\"CLAIMANT_DATE_OF_BIRTH\"])\n",
    "        self.raw_per_df[\"CLAIM_APPLICATION_FILE_DATE\"] = pd.to_datetime(self.raw_per_df[\"CLAIM_APPLICATION_FILE_DATE\"])\n",
    "        self.raw_per_df[\"AGE\"] = (self.raw_per_df[\"CLAIM_APPLICATION_FILE_DATE\"] - self.raw_per_df[\"CLAIMANT_DATE_OF_BIRTH\"]).astype('<m8[Y]')\n",
    "        self.raw_per_df['SENIORCITIZEN'] = self.raw_per_df[\"AGE\"].gt(60).astype('int')\n",
    "        self.raw_per_df['AGE_BUCKET'] = pd.cut(self.raw_per_df['AGE'], [-999, 16, 40, 60, 80, 999], labels=['< 16', '16-40', '41-60','61-80','> 80'])\n",
    "        self.raw_per_df[\"INVALID_DOB\"] = (self.raw_per_df[\"AGE\"].lt(16) | self.raw_per_df[\"AGE\"].gt(80)).astype('int')\n",
    "        #Claimant Bank related features\n",
    "        # This condition in query checks the column isnull using the condition in query. REFER https://stackoverflow.com/a/46021212/5462372 for below code in query. \n",
    "        self.raw_per_df['IS_ACC_MISSING'] = self.raw_per_df.query(\"CLAIMANT_BANK_ACCOUNT_NUMBER != CLAIMANT_BANK_ACCOUNT_NUMBER\")[\"CLAIMANT_PAYMENT_MODE\"].eq(\"D\").astype('int')\n",
    "        self.raw_per_df['IS_ACC_MISSING'].fillna(0, inplace=True)\n",
    "        #Check if there is any attempt to bank fruad using payment mode of Debit card and mailing & residential address is not matching\n",
    "        self.raw_per_df['IS_BANKING_FRAUD'] = (self.raw_per_df[\"CLAIMANT_PAYMENT_MODE\"].eq(\"D\") & self.raw_per_df[\"NOT_SAME_MAIL_RES_ADDR\"].eq(0)).astype('int')\n",
    "        #Required for visualization purpose\n",
    "        self.raw_per_df[\"YEAR\"] = self.raw_per_df[\"CLAIM_APPLICATION_FILE_DATE\"].dt.year\n",
    "        self.raw_per_df[\"MONTH\"] = self.raw_per_df[\"CLAIM_APPLICATION_FILE_DATE\"].dt.month\n",
    "        self.raw_per_df[\"WEEK\"] = self.raw_per_df[\"CLAIM_APPLICATION_FILE_DATE\"].dt.weekofyear\n",
    "        self.raw_per_df['YEAR_MONTH'] = self.raw_per_df['CLAIM_APPLICATION_FILE_DATE'].dt.strftime('%Y-%m')\n",
    "        self.raw_per_df[\"YEAR_WEEK\"] = self.raw_per_df['CLAIM_APPLICATION_FILE_DATE'].dt.strftime('%Y-%W')\n",
    "\n",
    "    def pi_theft_feature(self):\n",
    "        '''\n",
    "        Email, Phone, bank account  and state id theft\n",
    "        '''\n",
    "        logger.info(\"pi_theft_feature\")\n",
    "        temp_df = self.raw_per_df[['CLAIMANT_ID','CLAIM_APPLICATION_ID','CLAIMANT_PHONE_NUMBER']].drop_duplicates(['CLAIMANT_ID','CLAIMANT_PHONE_NUMBER'],keep= 'last')\n",
    "        dict_phone = dict(temp_df.CLAIMANT_PHONE_NUMBER.value_counts() > 3)\n",
    "        self.raw_per_df['PHONE_THEFT'] = self.raw_per_df['CLAIMANT_PHONE_NUMBER'].map(dict_phone)\n",
    "\n",
    "        temp_df = self.raw_per_df[['CLAIMANT_ID','CLAIM_APPLICATION_ID','EMAIL']].query('EMAIL==EMAIL').drop_duplicates(['CLAIMANT_ID','EMAIL'],keep= 'last')\n",
    "        dict_email = dict(temp_df.EMAIL.value_counts() > 3)\n",
    "        self.raw_per_df['EMAIL_THEFT'] = self.raw_per_df['EMAIL'].map(dict_email)\n",
    "\n",
    "        temp_df = self.raw_per_df[['CLAIMANT_ID','CLAIM_APPLICATION_ID','CLAIMANT_BANK_ACCOUNT_NUMBER']].query('CLAIMANT_BANK_ACCOUNT_NUMBER==CLAIMANT_BANK_ACCOUNT_NUMBER').drop_duplicates(['CLAIMANT_ID','CLAIMANT_BANK_ACCOUNT_NUMBER'],keep= 'last')\n",
    "        dict_acc = dict(temp_df.CLAIMANT_BANK_ACCOUNT_NUMBER.value_counts()>1)\n",
    "        self.raw_per_df['ACC_NUMBER_THEFT'] = self.raw_per_df['CLAIMANT_BANK_ACCOUNT_NUMBER'].map(dict_acc)\n",
    "\n",
    "        temp_df = self.raw_per_df[['CLAIMANT_ID','CLAIM_APPLICATION_ID','CLAIMANT_STATE_ID_NO']].query('CLAIMANT_STATE_ID_NO==CLAIMANT_STATE_ID_NO').drop_duplicates(['CLAIMANT_ID','CLAIMANT_STATE_ID_NO'],keep= 'last')\n",
    "        dict_stateid = dict(temp_df.CLAIMANT_STATE_ID_NO.value_counts()>1)\n",
    "        self.raw_per_df['STATE_ID_THEFT'] = self.raw_per_df['CLAIMANT_STATE_ID_NO'].map(dict_stateid)\n",
    "\n",
    "        del temp_df\n",
    "        gc.collect()\n",
    "        \n",
    "    def freq_addr_change(self):\n",
    "        '''\n",
    "        Frequent Mailing and residential address, bank account and state id change\n",
    "        '''\n",
    "        logger.info(\"freq_addr_change\")\n",
    "        per_resaddr_cnt_df = self.raw_per_df.groupby('CLAIMANT_ID')['RES_ADDR'].nunique().reset_index().rename(columns={'RES_ADDR':'RES_ADDR_COUNT'})\n",
    "        per_resaddr_cnt_df['IS_FREQ_RES_ADDR_CHANGE'] = 0\n",
    "        per_resaddr_cnt_df['IS_FREQ_RES_ADDR_CHANGE'] = per_resaddr_cnt_df[\"RES_ADDR_COUNT\"].gt(2).astype('int')\n",
    "\n",
    "        self.raw_per_df = self.raw_per_df.merge(per_resaddr_cnt_df[['CLAIMANT_ID','IS_FREQ_RES_ADDR_CHANGE']], on='CLAIMANT_ID', how='left')\n",
    "        del per_resaddr_cnt_df\n",
    "\n",
    "        per_mailaddr_cnt_df = self.raw_per_df.groupby('CLAIMANT_ID')['MAIL_ADDR'].nunique().reset_index().rename(columns={'MAIL_ADDR':'MAIL_ADDR_COUNT'})\n",
    "        per_mailaddr_cnt_df['IS_FREQ_MAIL_ADDR_CHANGE'] = 0\n",
    "        per_mailaddr_cnt_df['IS_FREQ_MAIL_ADDR_CHANGE'] = per_mailaddr_cnt_df[\"MAIL_ADDR_COUNT\"].gt(2).astype('int')\n",
    "\n",
    "        self.raw_per_df = self.raw_per_df.merge(per_mailaddr_cnt_df[['CLAIMANT_ID','IS_FREQ_MAIL_ADDR_CHANGE']], on='CLAIMANT_ID', how='left')\n",
    "        del per_mailaddr_cnt_df\n",
    "\n",
    "       \n",
    "        per_bankacc_cnt_df = self.raw_per_df.groupby('CLAIMANT_ID')['CLAIMANT_BANK_ACCOUNT_NUMBER'].nunique().reset_index().rename(columns={'CLAIMANT_BANK_ACCOUNT_NUMBER':'BANK_ACC_COUNT'})\n",
    "        per_bankacc_cnt_df['IS_FREQ_BANK_ACC_CHANGE'] = 0\n",
    "        per_bankacc_cnt_df['IS_FREQ_BANK_ACC_CHANGE'] = per_bankacc_cnt_df[\"BANK_ACC_COUNT\"].gt(1).astype('int')\n",
    "\n",
    "        self.raw_per_df = self.raw_per_df.merge(per_bankacc_cnt_df[['CLAIMANT_ID','IS_FREQ_BANK_ACC_CHANGE']], on='CLAIMANT_ID', how='left')\n",
    "        del per_bankacc_cnt_df\n",
    "\n",
    "        per_stateid_cnt_df = self.raw_per_df.groupby('CLAIMANT_ID')['CLAIMANT_STATE_ID_NO'].nunique().reset_index().rename(columns={'CLAIMANT_STATE_ID_NO':'STATE_ID_COUNT'})\n",
    "        per_stateid_cnt_df['IS_FREQ_STATE_ID_CHANGE'] = 0\n",
    "        per_stateid_cnt_df['IS_FREQ_STATE_ID_CHANGE'] = per_stateid_cnt_df[\"STATE_ID_COUNT\"].gt(1).astype('int')\n",
    "\n",
    "        self.raw_per_df = self.raw_per_df.merge(per_stateid_cnt_df[['CLAIMANT_ID','IS_FREQ_STATE_ID_CHANGE']], on='CLAIMANT_ID', how='left')\n",
    "        del per_stateid_cnt_df\n",
    "        \n",
    "    def pi_suspicious(self):\n",
    "        '''\n",
    "        Features for suspicious DOB, skill set and education level from historical activities\n",
    "        '''\n",
    "        logger.info(\"pi_suspicious\")\n",
    "        \n",
    "        claimant_df = self.raw_per_df.copy()\n",
    "        per_dob_cnt_df = self.claimant_history_personal_details.groupby('CLAIMANT_ID')['CLAIMANT_DATE_OF_BIRTH'].nunique().reset_index().rename(columns={'CLAIMANT_DATE_OF_BIRTH':'DOB_COUNT'})\n",
    "        per_dob_cnt_df['IS_suspicious_DOB'] = 0\n",
    "        per_dob_cnt_df['IS_suspicious_DOB'] = per_dob_cnt_df[\"DOB_COUNT\"].gt(1).astype('int')\n",
    "\n",
    "        claimant_df = claimant_df.merge(per_dob_cnt_df, on='CLAIMANT_ID', how='left')\n",
    "        del per_dob_cnt_df\n",
    "        \n",
    "        #education change change - If the claimant shows less qualified compared to last application ID\n",
    "        self.claimant_history_personal_details.dropna(axis=0, subset=[\"CLAIMANT_EDUCATION_LEVEL_CODE\"], inplace=True)\n",
    "        self.claimant_history_personal_details.sort_values(by=['CLAIMANT_ID','CLAIM_APPLICATION_ID'], inplace=True)\n",
    "\n",
    "        #educational level more than what they have mentioned last time\n",
    "\n",
    "        self.claimant_history_personal_details[\"CLAIMANT_EDUCATION_LEVEL_CODE_typed\"] = self.claimant_history_personal_details[\"CLAIMANT_EDUCATION_LEVEL_CODE\"].replace({\"BD\": \"15\", \"HD\": \"15\", \"AD\": \"15\", \"GD\": \"15\",\n",
    "                                                                                   \"PD\": \"20\",\"PD  \": \"20\", \"CC\": \"12\",\"CC  \": \"12\", \"MD\": \"17\",\"MD  \": \"17\", \"HD  \": \"15\", \"BD  \": \"15\",\"AD  \": \"15\", \"GD  \": \"15\"})\n",
    "        self.claimant_history_personal_details[\"CLAIMANT_EDUCATION_LEVEL_CODE_typed\"] = self.claimant_history_personal_details[\"CLAIMANT_EDUCATION_LEVEL_CODE_typed\"].astype(\"int\")\n",
    "\n",
    "        #education change change\n",
    "        # Get non-duplicate rows based on CLAIMANT_ID column value and from that create a dict \n",
    "        # with CLAIMANT_ID as key and CLAIMANT_EDUCATION_LEVEL_CODE_typed as value. This dict represents\n",
    "        # the first education level registered for each CLAIMANT_ID.\n",
    "        edu_level_dict = self.claimant_history_personal_details.loc[~self.claimant_history_personal_details[\"CLAIMANT_ID\"].duplicated(), [\"CLAIMANT_ID\", \"CLAIMANT_EDUCATION_LEVEL_CODE_typed\"]].set_index(\"CLAIMANT_ID\")[\"CLAIMANT_EDUCATION_LEVEL_CODE_typed\"].to_dict()\n",
    "        # Create a temporary dataframe with only duplicate rows based on CLAIMANT_ID column value.\n",
    "        # This represents the subsequent education levels registered for each CLAIMANT_ID.\n",
    "        duplicates = self.claimant_history_personal_details.loc[self.claimant_history_personal_details[\"CLAIMANT_ID\"].duplicated(), [\"CLAIMANT_ID\", \"CLAIMANT_EDUCATION_LEVEL_CODE_typed\"]]\n",
    "        # Map a new column PREV_EDUCATION_LEVEL using CLAIMANT_ID and edu_level_dict.\n",
    "        duplicates[\"PREV_EDUCATION_LEVEL\"] = duplicates[\"CLAIMANT_ID\"].map(edu_level_dict)\n",
    "        # Select CLAIMANT_ID into a list where PREV_EDUCATION_LEVEL is greater than current education level (CLAIMANT_EDUCATION_LEVEL_CODE_typed)\n",
    "        fraud_claimant_id_edu_level = duplicates.loc[duplicates[\"PREV_EDUCATION_LEVEL\"] > duplicates[\"CLAIMANT_EDUCATION_LEVEL_CODE_typed\"], \"CLAIMANT_ID\"].drop_duplicates().tolist()\n",
    "        # fraud_claimant_id_edu_level         \n",
    "\n",
    "        # Claimant_History_Personal_Details_EDU\n",
    "\n",
    "        claimant_df[\"Is_suspicious_education\"] = 0\n",
    "        claimant_df.loc[(claimant_df[\"CLAIMANT_ID\"].isin(fraud_claimant_id_edu_level)), \"Is_suspicious_education\"] = 1\n",
    "        \n",
    "        #ambiguous skill details - If the claimants current application skill details are not matching with their previous mentioned skill details\n",
    "        # missing_value_describe(Claimant_History_Skill_Details)\n",
    "\n",
    "        claim_application_skill_dict = self.claimant_history_skill_details.groupby(\"CLAIM_APPLICATION_ID\")[\"SKILL_SET_CODE\"].apply(list).to_dict()\n",
    "\n",
    "\n",
    "        # claim_application_skill_dict\n",
    "        # concatenate skill code groupby CLAIM_APPLICATION_ID\n",
    "        # now for each claimant id, compare the skills from the previous claimant if any matches, add the skill code against that claimant id\n",
    "        # if it doesn't matches then add that claimant id to the list\n",
    "\n",
    "\n",
    "        claimant_skill_dict = {}\n",
    "        fraud_claimant_id_skill_set = []\n",
    "        for index, value in self.claimant_history_skill_details.iterrows():\n",
    "            claim_application_id = value[\"CLAIM_APPLICATION_ID\"]\n",
    "            claimant_id = value[\"CLAIMANT_ID\"]\n",
    "            claimant_skills = claim_application_skill_dict[claim_application_id]\n",
    "            if claimant_id in claimant_skill_dict.keys():\n",
    "                prev_claimant_skills = claimant_skill_dict[claimant_id]\n",
    "                if (set(claimant_skills) & set(prev_claimant_skills)):\n",
    "                    claimant_skill_dict[claimant_id] = claimant_skills + prev_claimant_skills\n",
    "                elif (len(prev_claimant_skills) == 1):\n",
    "                    claimant_skill_dict[claimant_id] = claimant_skills + prev_claimant_skills\n",
    "                else:    \n",
    "                    fraud_claimant_id_skill_set.append(claimant_id)\n",
    "            else:\n",
    "                claimant_skill_dict[claimant_id] = claimant_skills\n",
    "        # fraud_claimant_id_skill_set    \n",
    "\n",
    "        # len(set(fraud_claimant_id_skill_set))\n",
    "\n",
    "        claimant_df[\"Is_suspicious_skill_history\"] = 0\n",
    "        claimant_df.loc[(claimant_df[\"CLAIMANT_ID\"].isin(fraud_claimant_id_skill_set)), \"Is_suspicious_skill_history\"] = 1\n",
    "        self.raw_per_df = claimant_df\n",
    "        del claimant_df\n",
    "        gc.collect()\n",
    "    \n",
    "    def skill_features(self):\n",
    "        '''\n",
    "        Skill related feature engineering\n",
    "        '''\n",
    "        logger.info(\"skill_features\")\n",
    "        raw_per_df = self.raw_per_df\n",
    "        skill_df = self.skill_df\n",
    "        #Need to get unique ones to make operations only for claimants that are present in claimant details file\n",
    "        skill_df.dropna(axis=0,inplace=True)\n",
    "\n",
    "        #Need to get unique ones to make operations only for claimants that are present in claimant details file\n",
    "        unique_claimant_id = list(raw_per_df[\"CLAIMANT_ID\"])\n",
    "\n",
    "        #Drop dupliclate data with same claimant id and CLAIMANT_SKILL_CODE\n",
    "        skill_df.drop_duplicates(subset=[\"CLAIMANT_ID\", \"CLAIMANT_SKILL_CODE\"], inplace=True)\n",
    "        #Remove records where claimant id not present in personal details data\n",
    "        skill_df = skill_df.loc[(skill_df[\"CLAIMANT_ID\"].isin(unique_claimant_id))]\n",
    "\n",
    "        skill_df['IS_SKILL_PREFERENCE_NOT_MATCHING'] = skill_df[\"IS_PRIMARY_SKILL_DECLARED_BY_CLAIMANT\"].eq(skill_df[\"IS_PREFERRED_SKILL_DECLARED_BY_CLAIMANT\"]).astype('int')\n",
    "\n",
    "        #find sum of the work experience for each claimant\n",
    "        pref_work_exp_df = skill_df.query('IS_PREFERRED_SKILL_DECLARED_BY_CLAIMANT==1').groupby([\"CLAIMANT_ID\"])['WORK_EXPERIENCE_IN_MONTHS'].agg(\"sum\").reset_index().rename(columns={'WORK_EXPERIENCE_IN_MONTHS':'PREF_WORK_EXP'})\n",
    "        skill_df = skill_df.merge(pref_work_exp_df, how='left', on='CLAIMANT_ID')\n",
    "\n",
    "        skill_df['SKILL_COUNT'] = skill_df.groupby(\"CLAIMANT_ID\")['CLAIMANT_SKILL_CODE'].transform(\"count\")\n",
    "\n",
    "        high_skill_count = max(skill_df.SKILL_COUNT.unique())\n",
    "\n",
    "        skill_df['VERY_HIGH_SKILL_COUNT'] = skill_df[\"SKILL_COUNT\"].ge(high_skill_count).astype('int')\n",
    "\n",
    "        #Removing records with no values in CLAIAMANT_SKILL_DESCRIPTION and CLAIMANT_SKILL_CODE\n",
    "        claimant_primary_skill = skill_df.loc[(skill_df[\"IS_PRIMARY_SKILL_DECLARED_BY_CLAIMANT\"] == 1.0)]\n",
    "        claimant_primary_skill = claimant_primary_skill.sort_values(\"CLAIM_APPLICATION_ID\").groupby(\"CLAIMANT_ID\").tail(1)\n",
    "\n",
    "        #Cumulative work experience\n",
    "        cumulative_work_exp = skill_df.groupby(['CLAIMANT_ID','CLAIMANT_SKILL_CODE'])['WORK_EXPERIENCE_IN_MONTHS'].max().reset_index(level=0)\n",
    "        cumulative_work_exp = cumulative_work_exp.groupby(['CLAIMANT_ID'])['WORK_EXPERIENCE_IN_MONTHS'].sum().reset_index()\n",
    "\n",
    "        #cumulative_work_exp\n",
    "\n",
    "        claimant_primary_skill = pd.merge(claimant_primary_skill, cumulative_work_exp, how=\"inner\", on=\"CLAIMANT_ID\")\n",
    "        #claimant_primary_skill\n",
    "        del cumulative_work_exp\n",
    "        claimant_primary_skill.drop([\"WORK_EXPERIENCE_IN_MONTHS_x\", \"IS_PRIMARY_SKILL_DECLARED_BY_CLAIMANT\", \"IS_PREFERRED_SKILL_DECLARED_BY_CLAIMANT\"], axis=1, inplace=True)\n",
    "        claimant_primary_skill.rename(columns={\"WORK_EXPERIENCE_IN_MONTHS_y\": \"WORK_EXPERIENCE_IN_MONTHS\"}, inplace=True)\n",
    "        \n",
    "        self.claimant_skill_df = claimant_primary_skill\n",
    "        gc.collect()\n",
    "    \n",
    "    def employer_features(self):\n",
    "        '''\n",
    "        Employer data preparation\n",
    "        '''\n",
    "        logger.info(\"employer_features\")\n",
    "        missing_val_map = {'04a4c7210f9df2d6a80433450b94d9007c97':np.NaN}\n",
    "        replace_dict = {'EMPLOYER_NAME':missing_val_map}\n",
    "        self.employer_df = self.employer_df.replace(to_replace=replace_dict)\n",
    "        employer_cols_to_keep = [\"EMPLOYER_ID\", \"REGISTRATION_DATE\",\"EMPLOYER_INDUSTRY_CODE\",\"EMPLOYER_INDUSTRY_DESC\",\\\n",
    "                         \"EMPLOYER_NAME\",\"MAIL_ADDRESS_STATE\",\"MAIL_ADDRESS_COUNTRY\"]\n",
    "        self.employer_df = self.employer_df[employer_cols_to_keep]\n",
    "        self.employer_df[\"REGISTRATION_DATE\"].fillna(\"2020-09-01\", inplace=True)\n",
    "        self.employer_df[\"EMPLOYER_INDUSTRY_CODE\"].fillna(-1, inplace=True)\n",
    "        self.employer_df[\"EMPLOYER_INDUSTRY_DESC\"].fillna(\"NA\", inplace=True)\n",
    "        self.employer_df[\"EMPLOYER_AGE\"] = self.employer_df[\"REGISTRATION_DATE\"].apply(lambda x : calculate_age(datetime.strptime(x, \"%Y-%m-%d\")))\n",
    "        self.employer_df[\"EMPLOYER_AGE\"] = self.employer_df[\"EMPLOYER_AGE\"].replace([2020], -1)\n",
    "        self.employer_df['EMP_AGE_BUCKET'] = pd.cut(self.employer_df['EMPLOYER_AGE'], [-999, 1, 5, 10, 15, 100], labels=['0-1', '1-5', '5-10','10-15','15-100'])\n",
    "    \n",
    "    def claimant_prev_fraud_history(self, temp_df):\n",
    "        logger.info(\"claimant_prev_fraud_history\")\n",
    "        is_train = self.is_train\n",
    "        #load the raw dataset if \n",
    "        is_prv_fraud_commit = []\n",
    "        previous_fraud_commit_claimants = {}\n",
    "        # logger.info (is_train)\n",
    "        if is_train == True:\n",
    "            temp_df = temp_df[['CLAIMANT_ID','CLAIM_APPLICATION_ID','FRAUD','CLAIM_APPLICATION_FILE_DATE']]\n",
    "            temp_df[\"is_prv_fraud_commit\"] = temp_df.groupby(\"CLAIMANT_ID\")['FRAUD'].shift().where(lambda s: s.eq(1))\n",
    "            is_prv_fraud_commit = temp_df.groupby(\"CLAIMANT_ID\")[\"is_prv_fraud_commit\"].ffill().fillna(0).astype(\"int\").tolist()\n",
    "        else:\n",
    "            raw_per_df = self.history_df\n",
    "            raw_per_df = raw_per_df.loc[raw_per_df[\"CLAIM_APPLICATION_FILE_DATE\"] >= self.input_dict[\"history_data_start_date\"]]\n",
    "            previous_fraud_commit_claimants = {x:1 for x in raw_per_df.loc[raw_per_df[\"FRAUD\"]==1, \"CLAIMANT_ID_x\"].to_numpy()}\n",
    "            is_prv_fraud_commit = temp_df[\"CLAIMANT_ID\"].map(previous_fraud_commit_claimants).fillna(0).tolist()\n",
    "        logger.info(f\"Length of previous_fraud_commit_claimants {len(previous_fraud_commit_claimants)}\")\n",
    "        return is_prv_fraud_commit\n",
    "                \n",
    "    def suspicious_employer(self, claimant_per_emp_sk_df):\n",
    "        logger.info(\"suspicious_employer\")\n",
    "        is_train = self.is_train\n",
    "        #in case of prediction it will not have the fraud labels, hence using the raw data created separately\n",
    "        if is_train == False:\n",
    "            claimant_temp_df = claimant_per_emp_sk_df.copy()\n",
    "            claimant_per_emp_sk_df = self.history_df\n",
    "            claimant_per_emp_sk_df = claimant_per_emp_sk_df.loc[claimant_per_emp_sk_df[\"CLAIM_APPLICATION_FILE_DATE\"] >= self.input_dict[\"history_data_start_date\"]]\n",
    "            \n",
    "        #TOCHECK changed to loc from query\n",
    "        claim_cnt = claimant_per_emp_sk_df.groupby(['EMPLOYER_ID'])['CLAIM_APPLICATION_ID'].count().reset_index().rename(columns={'CLAIM_APPLICATION_ID':'CLAIM_CNT'})\n",
    "        fraud_cnt = claimant_per_emp_sk_df.loc[claimant_per_emp_sk_df[\"FRAUD\"] == 1].groupby(['EMPLOYER_ID'])['CLAIM_APPLICATION_ID'].count().reset_index().rename(columns={'CLAIM_APPLICATION_ID':'FRAUD_CNT'})\n",
    "        claim_fraud_cnt = pd.merge(claim_cnt, fraud_cnt, how=\"left\", on=[\"EMPLOYER_ID\"])\n",
    "\n",
    "        claim_fraud_cnt.fillna(0, inplace=True)\n",
    "        claim_fraud_cnt['FRAUD_RATIO'] = round(claim_fraud_cnt.FRAUD_CNT/claim_fraud_cnt.CLAIM_CNT, 2)\n",
    "        claim_fraud_cnt['IS_SUSPICIOUS_EMPLOYER'] = claim_fraud_cnt[\"FRAUD_RATIO\"].gt(0.5).astype('int')\n",
    "        \n",
    "        if is_train == False:\n",
    "            claimant_per_emp_sk_df = claimant_temp_df.copy()\n",
    "            del claimant_temp_df\n",
    "        del claim_cnt, fraud_cnt\n",
    "        \n",
    "        claimant_per_emp_sk_df = pd.merge(claimant_per_emp_sk_df, claim_fraud_cnt[['EMPLOYER_ID','IS_SUSPICIOUS_EMPLOYER']], how=\"left\", on=[\"EMPLOYER_ID\"])\n",
    "        claimant_per_emp_sk_df['IS_SUSPICIOUS_EMPLOYER'].fillna(0,inplace=True)\n",
    "        logger.info (\"claimant_per_emp_sk_df suspicious_employer function\")\n",
    "        return claimant_per_emp_sk_df\n",
    "        \n",
    "    \n",
    "    def employment_features(self):\n",
    "        logger.info(\"employment_features\")\n",
    "        is_train = self.is_train\n",
    "        '''\n",
    "        Employment data preparation      \n",
    "        '''\n",
    "        employment_df = self.employment_df\n",
    "        employer_df = self.employer_df\n",
    "        raw_per_df = self.raw_per_df\n",
    "        claimant_skill_df = self.claimant_skill_df\n",
    "        missing_val_map = {'04a4c7210f9df2d6a80433450b94d9007c97':np.NaN}\n",
    "        replace_dict = {'CLAIM_APPLICATION_EMPLOYER_NAME':missing_val_map}\n",
    "        employment_df = employment_df.replace(to_replace=replace_dict)\n",
    "        \n",
    "        #Remove columns which are not making any sense  \n",
    "        emp_cols_to_drop = ['EMPLOYER_REGISTERD_NAME_DIFFERS','CLAIM_APPLICATION_EMPLOYER_ADDRESS_LINE2',\\\n",
    "                    'CLAIMANT_WORKED_IN_CITY','CLAIMANT_WORKED_IN_STATE',\\\n",
    "                    'CLAIM_APPLICATION_EMPLOYER_ADDRESS_LINE1','CLAIM_APPLICATION_EMPLOYER_ZIP',\\\n",
    "                    'CLAIM_APPLICATION_EMPLOYER_CITY']\n",
    "        employment_df = clean_data(employment_df,emp_cols_to_drop)\n",
    "        #Imputing missing values\n",
    "        employment_df.drop_duplicates(subset=[\"CLAIMANT_ID\", \"CLAIM_APPLICATION_ID\"], inplace=True)        \n",
    "        employment_df[\"CLAIMANT_MENTIONED_PAY_RATE\"].fillna(0, inplace=True)\n",
    "        # Impute the missing pay rate by hour as the average PAY RATE is ~7\n",
    "        employment_df[\"CLAIMANT_MENTIONED_PAY_RATE_FREQUENCY\"].fillna(\"MONT\", inplace=True)\n",
    "        # The below feature is matching for all now.\n",
    "        employment_df['IS_EMPLOYER_MISSING'] = (~(employment_df[\"EMPLOYER_ID\"].notnull() & employment_df[\"CLAIM_APPLICATION_EMPLOYER_NAME\"].notnull())).astype('int')\n",
    "        #Merge employer and employment details for further calcualtion\n",
    "        employer_employee_df = pd.merge(employment_df, employer_df, how=\"left\", on=[\"EMPLOYER_ID\"])\n",
    "        \n",
    "        del employment_df\n",
    "        del employer_df\n",
    "        gc.collect()\n",
    "        employer_employee_df[\"CLAIMANT_MENTIONED_PAY_RATE_FREQUENCY\"] = employer_employee_df[\"CLAIMANT_MENTIONED_PAY_RATE_FREQUENCY\"].map({\" \": \"\", \"HOUR\": 720.0, \"WEEK\" :4.0, \n",
    "                                                                                    \"YEAR\" : 0.083, \"BIWK\": 2.0, \"MONT\":1.0, \"DAY\":30.0, \"DAY \":30.0}).astype(\"float\")\n",
    "        # All mismatched values will become 1.0 (MONT) by default.\n",
    "        employer_employee_df[\"CLAIMANT_MENTIONED_PAY_RATE_FREQUENCY\"].fillna(1.0, inplace=True)\n",
    "        employer_employee_df[\"CLAIMANT_MENTIONED_PAY\"] = employer_employee_df.CLAIMANT_MENTIONED_PAY_RATE * employer_employee_df.CLAIMANT_MENTIONED_PAY_RATE_FREQUENCY\n",
    " \n",
    "        emp_cols_to_keep = ['CLAIMANT_ID', 'CLAIM_APPLICATION_ID','CLAIMANT_MENTIONED_PAY','IS_EMPLOYER_MISSING',\\\n",
    "                    'CLAIM_APPLICATION_EMPLOYER_STATE','CLAIM_APPLICATION_EMPLOYER_ADDRESS_CITY',\\\n",
    "                    'SEPARATION_REASON_WITH_EMPLOYER','JOBTITLE_MENTIONED_BY_EMPLOYER',\"EMPLOYER_ID\",'EMP_AGE_BUCKET',\\\n",
    "                    'EMPLOYER_INDUSTRY_CODE',\"EMPLOYER_INDUSTRY_DESC\",'EMPLOYER_WAS_NOT_PRESENT_IN_SYSTEM','EMPLOYER_TYPE','EMPLOYER_NAME']\n",
    "\n",
    "        claimant_emp = employer_employee_df[emp_cols_to_keep]\n",
    "        \n",
    "        '''\n",
    "        Merge Employment and personal details\n",
    "        '''\n",
    "        claimant_per_emp_df = pd.merge(raw_per_df, claimant_emp, how=\"left\", on=[\"CLAIMANT_ID\", \"CLAIM_APPLICATION_ID\"])\n",
    "        \n",
    "        '''\n",
    "        Merge again with skill dataset using claimant_id column\n",
    "        '''\n",
    "        claimant_per_emp_sk_df = pd.merge(claimant_per_emp_df, claimant_skill_df, how=\"left\", on=[\"CLAIMANT_ID\", \"CLAIM_APPLICATION_ID\"])\n",
    "        \n",
    "        claimant_per_emp_sk_df['IS_WORK_EXP_AMBIGIOUS'] = claimant_per_emp_sk_df[\"WORK_EXPERIENCE_IN_MONTHS\"].gt(claimant_per_emp_sk_df[\"AGE\"].multiply(12).subtract(16)).astype('int')\n",
    "        \n",
    "        '''\n",
    "        County wise education wise skill wise earning on basic pay-> suspicious employer\n",
    "        \n",
    "        '''\n",
    "\n",
    "        claimant_per_emp_sk_df[\"CLAIMANT_EDUCATION_LEVEL_CODE\"] = claimant_per_emp_sk_df.query('CLAIMANT_EDUCATION_LEVEL_CODE == CLAIMANT_EDUCATION_LEVEL_CODE')[\"CLAIMANT_EDUCATION_LEVEL_CODE\"].replace({\"BD\": \"15\", \"HD\": \"15\", \"AD\": \"15\", \"GD\": \"15\",\n",
    "                                                                                   \"PD\": \"20\",\"PD  \": \"20\", \"CC\": \"12\",\"CC  \": \"12\", \"MD\": \"17\",\"MD  \": \"17\", \"HD  \": \"15\", \"BD  \": \"15\",\"AD  \": \"15\", \"GD  \": \"15\"})\n",
    "        claimant_per_emp_sk_df[\"CLAIMANT_EDUCATION_LEVEL_CODE\"] = claimant_per_emp_sk_df.query('CLAIMANT_EDUCATION_LEVEL_CODE == CLAIMANT_EDUCATION_LEVEL_CODE')[\"CLAIMANT_EDUCATION_LEVEL_CODE\"].astype(\"int\")\n",
    "        skill_education_pay_df = claimant_per_emp_sk_df.groupby([\"CLAIMANT_SKILL_CODE\", \"CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID\", \"CLAIMANT_EDUCATION_LEVEL_CODE\"]).agg({\"CLAIMANT_MENTIONED_PAY\": [q1_quantile, q2_quantile, q3_quantile, \"max\"]})\n",
    "\n",
    "        skill_education_pay_df.columns = skill_education_pay_df.columns.droplevel(0)\n",
    "        skill_education_pay_df.reset_index(inplace=True)\n",
    "        skill_education_pay_df.dropna(axis=0, inplace=True)\n",
    "        \n",
    "        skill_education_pay_df[\"upper_count\"] = skill_education_pay_df[\"q3_quantile\"].add(skill_education_pay_df[\"q3_quantile\"].subtract(skill_education_pay_df[\"q1_quantile\"]).multiply(1.5))\n",
    "        skill_education_pay_df.drop_duplicates(subset=[\"CLAIMANT_SKILL_CODE\", \"CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID\", \"CLAIMANT_EDUCATION_LEVEL_CODE\"], inplace=True)\n",
    "        upper_count_skill_education_dict = {}\n",
    "\n",
    "        skill_education_pay_df[\"county_skill_education\"] = skill_education_pay_df[\"CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID\"].astype(str)+ \\\n",
    "                \":\" + skill_education_pay_df[\"CLAIMANT_SKILL_CODE\"].astype(str) + \\\n",
    "                \":\" + skill_education_pay_df[\"CLAIMANT_EDUCATION_LEVEL_CODE\"].astype(float).astype(str)\n",
    "        upper_count_skill_education_dict = skill_education_pay_df.set_index(\"county_skill_education\")[\"q3_quantile\"].to_dict()\n",
    "        # upper_count_skill_education_dict\n",
    "\n",
    "        claimant_per_emp_sk_df[\"county_skill_education\"] = claimant_per_emp_sk_df[\"CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID\"].astype(str)+ \\\n",
    "                \":\" + claimant_per_emp_sk_df[\"CLAIMANT_SKILL_CODE\"].astype(str) + \\\n",
    "                \":\" + claimant_per_emp_sk_df[\"CLAIMANT_EDUCATION_LEVEL_CODE\"].astype(float).astype(str)\n",
    "            \n",
    "        m = claimant_per_emp_sk_df[\"county_skill_education\"].map(upper_count_skill_education_dict)\n",
    "        m[pd.isnull(m)]=0\n",
    "        anomaly_arr = np.where(m, \\\n",
    "            claimant_per_emp_sk_df[\"CLAIMANT_MENTIONED_PAY\"].gt(claimant_per_emp_sk_df[\"county_skill_education\"].map(upper_count_skill_education_dict)).astype('int'), \\\n",
    "            -1)\n",
    "        claimant_per_emp_sk_df[\"is_suspicious_wage_base_period\"] = anomaly_arr\n",
    "\n",
    "        # unemployment_df  \n",
    "        '''\n",
    "        Get the fraud history\n",
    "        \n",
    "        '''\n",
    "        claimant_per_emp_sk_df = claimant_per_emp_sk_df.sort_values(by=['CLAIMANT_ID','CLAIM_APPLICATION_FILE_DATE'])\n",
    "        #few features require the fraud and employer id data\n",
    "        if not is_train:\n",
    "            input_dict = self.input_dict\n",
    "            logger.info(\"Reading files historical claimant personal details.\")\n",
    "            raw_history_df_path = os.path.join(self.input_file_path, input_dict[\"raw_per_df_history\"])\n",
    "            raw_history_df = self._read_csv_folder(raw_history_df_path, low_memory=False, usecols = ['CLAIMANT_ID_x','CLAIM_APPLICATION_FILE_DATE','CLAIM_APPLICATION_ID', 'FRAUD'], converters=self.cols_dtype_dict)\n",
    "            if not self.interim_df.empty:\n",
    "                logger.info(\"Merging claimnat personal details interim data during scoring\")\n",
    "                interim_df = self.interim_df[['CLAIMANT_ID_x','CLAIM_APPLICATION_FILE_DATE','CLAIM_APPLICATION_ID', 'FRAUD']]\n",
    "                raw_history_df = pd.concat([raw_history_df, interim_df], sort=True).reset_index(drop=True)\n",
    "            raw_emp_history_df = self.employment_df[['CLAIMANT_ID','EMPLOYER_ID']]\n",
    "            raw_history_df = pd.merge(raw_history_df, raw_emp_history_df, how=\"left\", left_on=\"CLAIMANT_ID_x\", right_on=\"CLAIMANT_ID\")\n",
    "            raw_history_df[\"EMPLOYER_ID\"].fillna(0, inplace=True)\n",
    "            raw_history_df[\"EMPLOYER_ID\"] = raw_history_df[\"EMPLOYER_ID\"].astype(int)\n",
    "            raw_history_df.drop(\"CLAIMANT_ID\", axis=1, inplace=True) #redundant CLAIMANT_ID columns exist\n",
    "            raw_history_df[\"CLAIM_APPLICATION_FILE_DATE\"] = pd.to_datetime(raw_history_df[\"CLAIM_APPLICATION_FILE_DATE\"], format=\"%d-%m-%Y\")\n",
    "            self.history_df = raw_history_df\n",
    "            del raw_emp_history_df, raw_history_df\n",
    "        \n",
    "        is_prv_fraud_commit = self.claimant_prev_fraud_history(claimant_per_emp_sk_df)\n",
    "        claimant_per_emp_sk_df['HAS_FRAUD_HISTORY'] = is_prv_fraud_commit\n",
    "        \n",
    "        '''\n",
    "        Check Fraud Employer\n",
    "        '''\n",
    "        claimant_per_emp_sk_df = self.suspicious_employer(claimant_per_emp_sk_df)\n",
    "        return claimant_per_emp_sk_df\n",
    "    \n",
    "    \n",
    "    def data_preparation(self): \n",
    "        '''\n",
    "        Special treatment for bank account and routing number\n",
    "        It looks like 04a4c7210f9df2d6a80433450b94d9007c97 value represents the missing value for bank account number and \n",
    "        routing number and state id\n",
    "        Remove duplicate and ambigious records , drop unwanted columns and rename column\n",
    "        '''\n",
    "        logger.info(\"data_preparation\")\n",
    "        logger.debug(f\"raw_per_df {self.raw_per_df.shape} Skill df {self.skill_df.shape}\\n \\\n",
    "            employment_df {self.employer_df.shape}  employer_df {self.employer_df.shape}\\n \\\n",
    "            Claimant_History_Personal_Details {self.claimant_history_personal_details.shape}\\n \\\n",
    "            Claimant_History_Skill_Details {self.claimant_history_skill_details.shape}\")\n",
    "        self.pi_missing_treatment()\n",
    "        \n",
    "        '''\n",
    "        Feature engineering for Personal Data\n",
    "        Bank account, State ID, Address matching, work and residential ZIP match\n",
    "        ''' \n",
    "        logger.debug(f\"raw_per_df {self.raw_per_df.shape} Skill df {self.skill_df.shape}\\n \\\n",
    "            employment_df {self.employer_df.shape}  employer_df {self.employer_df.shape}\\n \\\n",
    "            Claimant_History_Personal_Details {self.claimant_history_personal_details.shape}\\n \\\n",
    "            Claimant_History_Skill_Details {self.claimant_history_skill_details.shape}\")\n",
    "        self.pi_match_feature()\n",
    "\n",
    "        '''\n",
    "        Email, Phone, bank account  and state id theft\n",
    "        ''' \n",
    "        logger.debug(f\"raw_per_df {self.raw_per_df.shape} Skill df {self.skill_df.shape}\\n \\\n",
    "            employment_df {self.employer_df.shape}  employer_df {self.employer_df.shape}\\n \\\n",
    "            Claimant_History_Personal_Details {self.claimant_history_personal_details.shape}\\n \\\n",
    "            Claimant_History_Skill_Details {self.claimant_history_skill_details.shape}\")\n",
    "        self.pi_theft_feature()\n",
    "\n",
    "        '''\n",
    "        Frequent Mailing and residential address, bank account and state id change\n",
    "        '''         \n",
    "        logger.debug(f\"raw_per_df {self.raw_per_df.shape} Skill df {self.skill_df.shape}\\n \\\n",
    "            employment_df {self.employer_df.shape}  employer_df {self.employer_df.shape}\\n \\\n",
    "            Claimant_History_Personal_Details {self.claimant_history_personal_details.shape}\\n \\\n",
    "            Claimant_History_Skill_Details {self.claimant_history_skill_details.shape}\")\n",
    "        self.freq_addr_change()\n",
    "       \n",
    "        '''\n",
    "        Features for suspicious DOB, skill set and education level from historical activities\n",
    "        '''        \n",
    "        logger.debug(f\"raw_per_df {self.raw_per_df.shape} Skill df {self.skill_df.shape}\\n \\\n",
    "            employment_df {self.employer_df.shape}  employer_df {self.employer_df.shape}\\n \\\n",
    "            Claimant_History_Personal_Details {self.claimant_history_personal_details.shape}\\n \\\n",
    "            Claimant_History_Skill_Details {self.claimant_history_skill_details.shape}\")\n",
    "        self.pi_suspicious()\n",
    "        \n",
    "        '''\n",
    "        Skill related feature engineering\n",
    "        '''\n",
    "        logger.debug(f\"raw_per_df {self.raw_per_df.shape} Skill df {self.skill_df.shape}\\n \\\n",
    "            employment_df {self.employer_df.shape}  employer_df {self.employer_df.shape}\\n \\\n",
    "            Claimant_History_Personal_Details {self.claimant_history_personal_details.shape}\\n \\\n",
    "            Claimant_History_Skill_Details {self.claimant_history_skill_details.shape}\")\n",
    "        self.skill_features()     \n",
    "   \n",
    "        '''\n",
    "        Employer data preparation\n",
    "        '''\n",
    "        logger.debug(f\"raw_per_df {self.raw_per_df.shape} Skill df {self.skill_df.shape}\\n \\\n",
    "            employment_df {self.employer_df.shape}  employer_df {self.employer_df.shape}\\n \\\n",
    "            Claimant_History_Personal_Details {self.claimant_history_personal_details.shape}\\n \\\n",
    "            Claimant_History_Skill_Details {self.claimant_history_skill_details.shape}\")\n",
    "        self.employer_features()\n",
    "        \n",
    "        '''\n",
    "        Employment data preparation\n",
    "        '''\n",
    "        logger.debug(f\"raw_per_df {self.raw_per_df.shape} Skill df {self.skill_df.shape}\\n \\\n",
    "            employment_df {self.employer_df.shape}  employer_df {self.employer_df.shape}\\n \\\n",
    "            Claimant_History_Personal_Details {self.claimant_history_personal_details.shape}\\n \\\n",
    "            Claimant_History_Skill_Details {self.claimant_history_skill_details.shape}\")\n",
    "        claimant_per_emp_sk_df = self.employment_features()\n",
    "        logger.debug(f\"claimant_per_emp_sk_df {claimant_per_emp_sk_df.shape}\")\n",
    "        logger.info(\"claimant_per_emp_sk_df before required features\")\n",
    "        # logger.info(claimant_per_emp_sk_df)\n",
    "        logger.debug(f\"raw_per_df {self.raw_per_df.shape} Skill df {self.skill_df.shape}\\n \\\n",
    "            employment_df {self.employer_df.shape}  employer_df {self.employer_df.shape}\\n \\\n",
    "            Claimant_History_Personal_Details {self.claimant_history_personal_details.shape}\\n \\\n",
    "            Claimant_History_Skill_Details {self.claimant_history_skill_details.shape}\")\n",
    "        \n",
    "        '''\n",
    "        Required features\n",
    "        '''\n",
    "        \n",
    "        document_direct_feature_list = ['CLAIMANT_ID', 'CLAIM_APPLICATION_ID', 'CLAIMANT_MAILING_ADDRESS_CITY', \\\n",
    "                                        'CLAIMANT_MAILING_ADDRESS_STATE',  'CLAIMANT_RESIDENTIAL_ADDRESS_CITY', \\\n",
    "                                        'CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_DESC', 'CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID', \\\n",
    "                                        'CLAIMANT_RESIDENTIAL_ADDRESS_STATE','CLAIMANT_OPTED_FOR_FEDERAL_TAX', 'CLAIMANT_PAYMENT_MODE',\\\n",
    "                                        \"CLAIM_APPLICATION_FILE_DATE\",\"CLAIMANT_OPTED_FOR_STATE_TAX\",\\\n",
    "\n",
    "                                        'CLAIMANT_SKILL_CODE', 'CLAIAMANT_SKILL_DESCRIPTION', 'CLAIMANT_EDUCATION_LEVEL_CODE',\\\n",
    "                                        'CLAIMANT_EDUCATION_LEVEL_DESC',\\\n",
    "\n",
    "                                        'EMPLOYER_ID','CLAIM_APPLICATION_EMPLOYER_ADDRESS_CITY','CLAIM_APPLICATION_EMPLOYER_STATE',\\\n",
    "                                        'EMPLOYER_INDUSTRY_CODE','EMPLOYER_INDUSTRY_DESC','EMPLOYER_TYPE','EMPLOYER_NAME',\\\n",
    "                                        'JOBTITLE_MENTIONED_BY_EMPLOYER','SEPARATION_REASON_WITH_EMPLOYER']\n",
    "        if self.is_train == True:\n",
    "            document_direct_feature_list.append('FRAUD')\n",
    "        document_derived_feature_list = ['AGE', 'AGE_BUCKET', 'SENIORCITIZEN',  'INVALID_DOB', 'IS_suspicious_DOB',\\\n",
    "                                         'IS_ID_NOT_LOCAL',  'STATE_ID_THEFT','IS_ID_MISSING','ID_EXPIRED',  'IS_ID_STATE_NOT_MATCHING_MAIL', 'IS_ID_STATE_NOT_MATCHING_RES',\\\n",
    "                                         'IS_ACC_MISSING','ACC_NUMBER_THEFT', 'IS_BANKING_FRAUD',\\\n",
    "                                         'IS_MAIL_STATE_NOT_LOCAL', 'IS_RES_STATE_NOT_LOCAL', 'CORRESPONDING_TOGETHER', 'LIVING_TOGETHER', 'RES_ADDR', 'NOT_SAME_MAIL_RES_ADDR', 'NOT_SAME_WORK_PRE_RES_ZIP',\\\n",
    "                                         'Is_suspicious_skill_history', 'VERY_HIGH_SKILL_COUNT', 'SKILL_COUNT', 'IS_SKILL_PREFERENCE_NOT_MATCHING', 'Is_suspicious_education',\\\n",
    "                                         'EMP_AGE_BUCKET', 'IS_EMPLOYER_MISSING' ,'WORK_EXPERIENCE_IN_MONTHS','CLAIMANT_MENTIONED_PAY', 'PREF_WORK_EXP','IS_WORK_EXP_AMBIGIOUS', 'is_suspicious_wage_base_period',\\\n",
    "                                         'EMAIL_THEFT', 'PHONE_THEFT',\\\n",
    "                                         'MONTH', 'WEEK', 'YEAR', 'YEAR_MONTH', 'YEAR_WEEK','HAS_FRAUD_HISTORY',\\\n",
    "                                         'IS_FREQ_RES_ADDR_CHANGE','IS_FREQ_MAIL_ADDR_CHANGE','IS_FREQ_BANK_ACC_CHANGE','IS_FREQ_STATE_ID_CHANGE','IS_SUSPICIOUS_EMPLOYER']\n",
    "        final_list = document_direct_feature_list + document_derived_feature_list\n",
    "\n",
    "        claimant_per_emp_sk_df.rename(columns={'IS_suspicious_DOB_x':'IS_suspicious_DOB'}, inplace=True)\n",
    "        \n",
    "        '''\n",
    "        We are going to work on this data set for visualization\n",
    "        '''\n",
    "        model_df = claimant_per_emp_sk_df[final_list].copy()\n",
    "        logger.debug(f\"model_df {model_df.shape}\")\n",
    "        # List of columns identified for imputation\n",
    "        fill_cols_m_one = ['ACC_NUMBER_THEFT','IS_suspicious_DOB','ID_EXPIRED','IS_ID_STATE_NOT_MATCHING_RES','IS_ID_STATE_NOT_MATCHING_MAIL',\\\n",
    "                   'STATE_ID_THEFT','IS_ID_NOT_LOCAL','VERY_HIGH_SKILL_COUNT','IS_SKILL_PREFERENCE_NOT_MATCHING',\\\n",
    "                   'EMAIL_THEFT','CLAIMANT_OPTED_FOR_STATE_TAX','CLAIMANT_OPTED_FOR_FEDERAL_TAX']\n",
    "        fill_cols_nd = ['EMP_AGE_BUCKET','EMPLOYER_INDUSTRY_DESC','EMPLOYER_INDUSTRY_CODE','EMPLOYER_ID','CLAIAMANT_SKILL_DESCRIPTION',\\\n",
    "                        'CLAIMANT_SKILL_CODE','SEPARATION_REASON_WITH_EMPLOYER','CLAIM_APPLICATION_EMPLOYER_ADDRESS_CITY', \\\n",
    "                        'CLAIM_APPLICATION_EMPLOYER_STATE','CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_DESC',\\\n",
    "                        'CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID','CLAIMANT_EDUCATION_LEVEL_DESC','CLAIMANT_EDUCATION_LEVEL_CODE',\\\n",
    "                        'JOBTITLE_MENTIONED_BY_EMPLOYER','EMPLOYER_TYPE','EMPLOYER_NAME'\n",
    "                        ]\n",
    "        fill_col_zero = ['SKILL_COUNT','WORK_EXPERIENCE_IN_MONTHS','PREF_WORK_EXP','CLAIMANT_MENTIONED_PAY']\n",
    "        fill_col_one = ['IS_EMPLOYER_MISSING']\n",
    "        '''\n",
    "        Impute missing values and convert all float columns to int and boolean to integer to save space\n",
    "        '''\n",
    "        model_df['EMP_AGE_BUCKET'] = model_df['EMP_AGE_BUCKET'].astype(object)\n",
    "        model_df.update(model_df[fill_cols_m_one].fillna(-1))\n",
    "        model_df.update(model_df[fill_col_zero].fillna(0))\n",
    "        model_df.update(model_df[fill_cols_nd].fillna('N/A'))\n",
    "        model_df.update(model_df[fill_col_one].fillna(1))\n",
    "\n",
    "        float_cols = model_df.select_dtypes(include='float64').columns\n",
    "        model_df[float_cols] = model_df[float_cols].astype(int)\n",
    "        \n",
    "        \n",
    "        theft_map = {False:0, True:1, -1:-1}\n",
    "        bool_cols = ['STATE_ID_THEFT','LIVING_TOGETHER','CORRESPONDING_TOGETHER','PHONE_THEFT','EMAIL_THEFT','ACC_NUMBER_THEFT', 'IS_SKILL_PREFERENCE_NOT_MATCHING']\n",
    "\n",
    "        model_df[bool_cols] = model_df[bool_cols].applymap(theft_map.get)\n",
    "        \n",
    "        fraud_indicator_df = model_df.copy()\n",
    "        \n",
    "        yesno_map = {0:'N', 1:'Y', -1:'N/A'}\n",
    "        yesno_cols = ['CLAIMANT_OPTED_FOR_FEDERAL_TAX','CLAIMANT_OPTED_FOR_STATE_TAX','SENIORCITIZEN','INVALID_DOB',\\\n",
    "                     'IS_suspicious_DOB','IS_ID_NOT_LOCAL','STATE_ID_THEFT','IS_ID_MISSING','ID_EXPIRED','IS_ID_STATE_NOT_MATCHING_MAIL',\\\n",
    "                     'IS_ID_STATE_NOT_MATCHING_RES','IS_ACC_MISSING','ACC_NUMBER_THEFT','IS_BANKING_FRAUD','IS_MAIL_STATE_NOT_LOCAL',\\\n",
    "                     'IS_RES_STATE_NOT_LOCAL','CORRESPONDING_TOGETHER','LIVING_TOGETHER','NOT_SAME_MAIL_RES_ADDR','NOT_SAME_WORK_PRE_RES_ZIP',\\\n",
    "                     'Is_suspicious_skill_history','VERY_HIGH_SKILL_COUNT','IS_SKILL_PREFERENCE_NOT_MATCHING','Is_suspicious_education',\\\n",
    "                     'IS_EMPLOYER_MISSING','IS_WORK_EXP_AMBIGIOUS','is_suspicious_wage_base_period','EMAIL_THEFT','PHONE_THEFT','HAS_FRAUD_HISTORY',\\\n",
    "                     'IS_FREQ_RES_ADDR_CHANGE','IS_FREQ_MAIL_ADDR_CHANGE','IS_FREQ_BANK_ACC_CHANGE','IS_FREQ_STATE_ID_CHANGE','IS_SUSPICIOUS_EMPLOYER']\n",
    "        fraud_indicator_df[yesno_cols] = fraud_indicator_df[yesno_cols].applymap(yesno_map.get)\n",
    "        if not self.is_train and self.fraud_indicator_cols:\n",
    "            try:         \n",
    "                indicator_df_cols = [\"CLAIMANT_ID\",\"CLAIM_APPLICATION_ID\"]\n",
    "                indicator_df_cols.extend(self.fraud_indicator_cols)\n",
    "                logger.info(f\"Fraud indicator columns {indicator_df_cols}\")\n",
    "                fraud_indicator_df = pd.melt(fraud_indicator_df[indicator_df_cols], id_vars=[\"CLAIMANT_ID\",\"CLAIM_APPLICATION_ID\"])\n",
    "                fraud_indicator_df.rename(columns={\"variable\":\"INDICATOR_NAME\", \"value\":\"INDICATOR_VALUE\"}, inplace=True)\n",
    "                fraud_indicator_df_path = os.path.join(self.input_dict[\"fraud_outputpath\"], self.input_dict[\"fraud_indicator\"], \"fraud_indicator.csv\")\n",
    "                csv_buffer = StringIO()\n",
    "                fraud_indicator_df.to_csv(csv_buffer, line_terminator=\"\\n\", index=False)\n",
    "                with self.fs.open(fraud_indicator_df_path, mode=\"wt\", encoding=\"utf-8\") as f:\n",
    "                    f.write(csv_buffer.getvalue())\n",
    "                logger.info(f\"Fraud indicators file generated at {fraud_indicator_df_path}.\")\n",
    "            except Exception as e:\n",
    "                traceback.print_exc(limit=100, file=sys.stdout)\n",
    "                logger.error(\"Error while generating fraud indicator file\", exc_info=True)\n",
    "        elif not self.is_train and not self.fraud_indicator_cols:\n",
    "            logger.warning(\"Fraud indicator column names are missing. Check initialisation of preprocessing class for details.\")\n",
    "        \n",
    "        '''\n",
    "        Start of model training data preparation\n",
    "        '''\n",
    "        # Step 1: Replace 0 with np.nan\n",
    "        model_df['CLAIMANT_MENTIONED_PAY'].replace({0:np.nan}, inplace=True)\n",
    "\n",
    "        # Step 2: Fill the pay using average of following fields\n",
    "        model_df['CLAIMANT_MENTIONED_PAY'] = model_df['CLAIMANT_MENTIONED_PAY'].fillna(\n",
    "            model_df.groupby(['EMPLOYER_INDUSTRY_CODE','CLAIMANT_MAILING_ADDRESS_STATE',\n",
    "                        'CLAIAMANT_SKILL_DESCRIPTION','CLAIMANT_EDUCATION_LEVEL_DESC','AGE'])['CLAIMANT_MENTIONED_PAY'].transform('mean').iloc[0]\n",
    "        )\n",
    "        \n",
    "        return model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UIModel():\n",
    "    def __init__(self, processed_df, input_dict, file_system, training=True):\n",
    "        logger.info(\"UIModel init\")\n",
    "        self.input_dict = input_dict\n",
    "        self.df = processed_df\n",
    "        self.selected_features = []\n",
    "        self.is_train = training\n",
    "        self.fs = file_system\n",
    "        self.supported_metrics = ['Sensitivity','Specificity','Precision','F1','ROC-AUC']\n",
    "        self.PCT_CHNG_ALLOWED = 5.0 # Range of percentage change in model metrics\n",
    "        self.TOP_FEATURES_N = 30 # Count of top features to be selected\n",
    "    # apply threshold to positive probabilities to create labels\n",
    "    def to_labels(self, pos_probs, threshold):\n",
    "        return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "    def clean_data(self, df_x, drop_cols_list):\n",
    "        logger.info(\"clean_data\")\n",
    "        present_cols = [col for col in drop_cols_list if col in df_x.columns]\n",
    "        df_x  = df_x.drop(present_cols, axis = 1)\n",
    "        logger.info(\"{} columns are present\".format(present_cols))\n",
    "        logger.info(f\"{list(set(drop_cols_list).difference(set(present_cols)))} columns are being being dropped.\")\n",
    "        return df_x\n",
    "\n",
    "    # evaluate a model\n",
    "    def evaluate_model(self, X, y, model,hyper_params,oversample=False):\n",
    "        logger.info(\"evaluate_model\")\n",
    "        rs_model = GridSearchCV(model, hyper_params, cv=2, n_jobs = -1)\n",
    "        if oversample==True:\n",
    "            method = SMOTE()\n",
    "            X_over, y_over = method.fit_sample(X, y)\n",
    "            rs_model.fit(X_over, y_over)\n",
    "        else:\n",
    "            rs_model.fit(X, y)\n",
    "\n",
    "        return rs_model\n",
    "\n",
    "    # define models to test\n",
    "    def get_models(self, model_list):\n",
    "        logger.info(\"get_models\")\n",
    "        models, names, hyper_params = list(), list(), list()\n",
    "        # CART\n",
    "        if 'DecisionTree' in model_list:\n",
    "            models.append(DecisionTreeClassifier())\n",
    "            names.append('DecisionTree')\n",
    "            hyper_params.append({'class_weight':[{0:0.106667, 1:0.89333},None]})\n",
    "\n",
    "        #LDA\n",
    "        if 'LDA' in model_list:\n",
    "            models.append(LinearDiscriminantAnalysis())\n",
    "            names.append('LDA')\n",
    "            hyper_params.append({'store_covariance':[True,False]})\n",
    "\n",
    "        # Bagging\n",
    "        if 'BaggingClassifier' in model_list:\n",
    "            models.append(BaggingClassifier(n_estimators=100))\n",
    "            names.append('BaggingClassifier')\n",
    "            hyper_params.append({'n_estimators':[10]})\n",
    "        # RF\n",
    "        if 'RandomForest' in model_list:    \n",
    "            models.append(RandomForestClassifier(n_estimators=100))\n",
    "            names.append('RandomForest')\n",
    "            hyper_params.append({'class_weight':[{0:0.106667, 1:0.89333},None]})\n",
    "        # ET\n",
    "        if 'ExtraTreeClassifier' in model_list:   \n",
    "            models.append(ExtraTreesClassifier(n_estimators=100))\n",
    "            names.append('ExtraTreeClassifier')\n",
    "            hyper_params.append({'n_estimators':[100]})\n",
    "        #XG\n",
    "        #scale_pos_weight = total_negative_examples / total_positive_examples\n",
    "        #For an imbalanced binary classification dataset, the negative class refers to the majority class (class 0) and the positive class refers to the minority class (class 1).\n",
    "        #359958/42146\n",
    "        if 'XGBoostClassifier' in model_list:   \n",
    "            models.append(XGBClassifier(booster='gbtree', n_jobs=-1))\n",
    "            names.append('XGBoostClassifier')\n",
    "            hyper_params.append({'scale_pos_weight':[1, 5.08]})\n",
    "\n",
    "        return models, names, hyper_params\n",
    "\n",
    "    #function to use for scoring \n",
    "    def get_classification_metrics(self, y_test,preds):\n",
    "        logger.info(\"get_classification_metrics\")\n",
    "        TN, FP, FN, TP = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "        sensi = TP/(TP + FN)\n",
    "        speci= TN/(TN + FP)\n",
    "        preci = TP/(TP + FP)\n",
    "        f1= 2*(preci*sensi)/(preci+sensi)\n",
    "        return round(sensi,3),round(speci,3),round(preci,3),round(f1,3)\n",
    "\n",
    "    def scores(self, t, name, x_train, x_test, y_train, y_test):\n",
    "        logger.info(\"scores\")\n",
    "\n",
    "        to_labels = self.to_labels\n",
    "        \n",
    "        default_metric = []\n",
    "        optimized_metric = []\n",
    "        logger.info(f\"{name} classification metric\")\n",
    "        train_score = round(t.score(x_train, y_train),3)\n",
    "        test_score =  round(t.score(x_test, y_test),3)\n",
    "\n",
    "        default_metric.append(train_score)\n",
    "        default_metric.append(test_score)\n",
    "        optimized_metric.append(train_score)\n",
    "        optimized_metric.append(test_score)    \n",
    "        #Evaluation metrics\n",
    "        predictions = t.predict(x_test)\n",
    "        sensi, speci,preci,f1 = self.get_classification_metrics(y_test, predictions)\n",
    "\n",
    "        default_metric.append(round(sensi,3))\n",
    "        default_metric.append(round(speci,3))\n",
    "        default_metric.append(round(preci,3))\n",
    "        default_metric.append(round(f1,3))\n",
    "\n",
    "        pred_proba = [i[1] for i in t.predict_proba(x_test)]\n",
    "        auc_score = roc_auc_score(y_test, pred_proba)\n",
    "        default_metric.append(round(auc_score,3))\n",
    "\n",
    "\n",
    "        logger.info(\"***********Result after threshold tuning***********\")\n",
    "        #Section below is for threshold tuning\n",
    "        # predict probabilities\n",
    "        yhat = t.predict_proba(x_test)\n",
    "        # keep probabilities for the positive outcome only\n",
    "        probs = yhat[:, 1]\n",
    "        # define thresholds\n",
    "        thresholds = np.arange(0, 1, 0.01)\n",
    "        # evaluate each threshold\n",
    "        pred_scores = [f1_score(y_test, to_labels(probs, t)) for t in thresholds]\n",
    "        # get best threshold\n",
    "        ix = np.argmax(pred_scores)\n",
    "        logger.info('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], pred_scores[ix]))\n",
    "\n",
    "        threshold = thresholds[ix]\n",
    "\n",
    "        predicted = t.predict_proba(x_test)\n",
    "        predicted[:,0] = (predicted[:,0] < threshold).astype('int')\n",
    "        predicted[:,1] = (predicted[:,1] >= threshold).astype('int')\n",
    "\n",
    "\n",
    "        #Evaluation metrics\n",
    "        #predictions = t.predict(x_test)\n",
    "        sensi, speci,preci,f1 = self.get_classification_metrics(y_test, predicted[:,1])\n",
    "\n",
    "        optimized_metric.append(round(sensi,3))\n",
    "        optimized_metric.append(round(speci,3))\n",
    "        optimized_metric.append(round(preci,3))\n",
    "        optimized_metric.append(round(f1,3))\n",
    "\n",
    "        auc_score = roc_auc_score(y_test, predicted[:,1])\n",
    "        optimized_metric.append(round(auc_score,3))\n",
    "        return default_metric, optimized_metric, threshold\n",
    "    \n",
    "    def limit_records_for_training(self, _date):\n",
    "        logger.info(\"limit_records_for_training\")\n",
    "        '''\n",
    "        ENABLE THE CELL BELOW TO LIMIT THE DATA FROM MAY-2020 ONWARDS (2020-05-01), i.e. last 6 months \n",
    "        '''\n",
    "        \n",
    "            \n",
    "        self.df[\"CLAIM_APPLICATION_FILE_DATE\"] = pd.to_datetime(self.df[\"CLAIM_APPLICATION_FILE_DATE\"])\n",
    "\n",
    "        \n",
    "        #the records only need to be limited for training and not prediction\n",
    "        if self.is_train == True:\n",
    "            self.df = self.df[self.df['CLAIM_APPLICATION_FILE_DATE']>=_date]            \n",
    "        cols_to_be_dropped = ['NOT_SAME_WORK_PRE_RES_ZIP','RES_ADDR','MONTH', 'WEEK', 'YEAR', 'YEAR_MONTH', 'YEAR_WEEK',\\\n",
    "                          'CLAIM_APPLICATION_FILE_DATE', 'AGE','CLAIAMANT_SKILL_DESCRIPTION','CLAIMANT_EDUCATION_LEVEL_DESC',\\\n",
    "                          'CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_DESC','EMPLOYER_INDUSTRY_DESC','JOBTITLE_MENTIONED_BY_EMPLOYER',\\\n",
    "                              'EMPLOYER_NAME', 'CLAIMANT_EDUCATION_LEVEL_CODE']\n",
    "        self.df = self.clean_data(self.df,cols_to_be_dropped)\n",
    "            \n",
    "    def data_transformation(self):\n",
    "        logger.info(\"data_transformation\")\n",
    "        cols_to_removed = ['IS_BANKING_FRAUD','IS_FREQ_RES_ADDR_CHANGE','IS_FREQ_MAIL_ADDR_CHANGE','IS_FREQ_BANK_ACC_CHANGE',\\\n",
    "                   'IS_FREQ_STATE_ID_CHANGE']\n",
    "        self.df = self.clean_data(self.df,cols_to_removed)\n",
    "        \n",
    "        '''\n",
    "        Categorical encoding\n",
    "        '''\n",
    "        #, 'WORK_EXPERIENCE_IN_MONTHS','AGE', \n",
    "        cont_var = ['PREF_WORK_EXP', 'SKILL_COUNT','CLAIMANT_MENTIONED_PAY','WORK_EXPERIENCE_IN_MONTHS']\n",
    "        nom_var = ['AGE_BUCKET', 'CLAIMANT_MAILING_ADDRESS_CITY', 'CLAIMANT_MAILING_ADDRESS_STATE', 'CLAIMANT_PAYMENT_MODE', 'CLAIMANT_RESIDENTIAL_ADDRESS_CITY',\n",
    "        'CLAIMANT_RESIDENTIAL_ADDRESS_COUNTY_ID', 'CLAIMANT_RESIDENTIAL_ADDRESS_STATE', 'CLAIMANT_SKILL_CODE', 'CLAIM_APPLICATION_EMPLOYER_ADDRESS_CITY', 'CLAIM_APPLICATION_EMPLOYER_STATE',\n",
    "        'EMPLOYER_INDUSTRY_CODE', 'EMP_AGE_BUCKET', 'SEPARATION_REASON_WITH_EMPLOYER']\n",
    "        \n",
    "        nom_var_object_type = self.df[self.df.columns.difference([\"CLAIMANT_ID\",\"CLAIM_APPLICATION_ID\"])].select_dtypes(include='object').columns.tolist()\n",
    "        nom_var = nom_var + nom_var_object_type\n",
    "        nom_var = list(set(nom_var)) \n",
    "\n",
    "        if (self.is_train == True):\n",
    "            X = self.df.drop([\"FRAUD\", \"CLAIMANT_ID\",\"CLAIM_APPLICATION_ID\"], axis=1)\n",
    "            logger.debug(X.columns)\n",
    "            y = self.df[\"FRAUD\"].values\n",
    "            cat_enc = MEstimateEncoder(cols=nom_var)\n",
    "            cat_enc.fit(X, y)\n",
    "            save_model(cat_enc, \"cat_transformation_ins.pkl\")\n",
    "            '''\n",
    "            Scaling\n",
    "            '''\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(X[cont_var])\n",
    "            save_model(scaler, \"min_max_transformation.pkl\")\n",
    "            df_encoded = cat_enc.transform(X)\n",
    "            df_encoded[\"FRAUD\"] = y\n",
    "        else:\n",
    "            #TODO: comment on why the encoding was not done from outside\n",
    "            X = self.df.drop([\"CLAIMANT_ID\",\"CLAIM_APPLICATION_ID\"], axis=1)\n",
    "            logger.debug(X.columns)\n",
    "            cat_enc = load_model(\"cat_transformation_ins.pkl\")\n",
    "            scaler = load_model(\"min_max_transformation.pkl\")\n",
    "            df_encoded = cat_enc.transform(X)\n",
    "        df_encoded.index = list(self.df[\"CLAIM_APPLICATION_ID\"])\n",
    "        df_encoded[cont_var] = scaler.transform(df_encoded[cont_var])\n",
    "        #TODO: Uncomment the below line after the NaN error got fixed.\n",
    "        df_encoded.fillna(0, inplace=True)\n",
    "        self.df = df_encoded\n",
    "        \n",
    "    \n",
    "    def select_model_features(self):\n",
    "        logger.info(\"select_model_features\")\n",
    "        self.check_for_retraining = True if (self.input_dict.get(\"check_for_retraining\", \"true\") == \"true\") else False\n",
    "        # Check if the model folder already has saved features from earlier training.\n",
    "        saved_features = None\n",
    "        try:\n",
    "            saved_features = load_model(\"selected_features.pkl\")\n",
    "        except:\n",
    "            logger.warning(\"No saved features file found from previous training.\")\n",
    "            logger.warning(\"Hence check_for_retraining flag set to FALSE.\")\n",
    "            self.check_for_retraining = False\n",
    "        # First time training and not retraining.\n",
    "        if self.is_train and not self.check_for_retraining:\n",
    "            logger.info(\"First time training and not checking for retraining\")\n",
    "            transformed_df = self.df\n",
    "            # Added forward fill for missing values\n",
    "            transformed_df = transformed_df.fillna(method='ffill')\n",
    "            x = transformed_df.drop(['FRAUD'], axis=1)\n",
    "            y = transformed_df['FRAUD']\n",
    "            features = x\n",
    "            labels = y\n",
    "           # 3. Variable Selection\n",
    "\n",
    "            # Feature selection methods\n",
    "\n",
    "            ## 3.1 WOE and IV\n",
    "            '''\n",
    "            #to be used later, for now throwing error\n",
    "            final_iv, IV = data_vars(df_final[df_final.columns.difference(['FRAUD'])],df_final.FRAUD)\n",
    "\n",
    "            IV = IV.rename(columns={'VAR_NAME':'index'})\n",
    "\n",
    "            '''\n",
    "    #         IV.sort_values(['IV'],ascending=0)\n",
    "\n",
    "            ## 3.2 Variable Importance using Random Forest \n",
    "            clf = RandomForestClassifier(n_estimators=100)\n",
    "            clf.fit(features,labels)\n",
    "            VI = pd.DataFrame(clf.feature_importances_, columns = [\"RF\"], index=features.columns)\n",
    "\n",
    "            ## 3.3 Recursive Feature Elimination\n",
    "            model = LogisticRegression(solver=\"lbfgs\", max_iter=999)\n",
    "            rfe = RFE(model, n_features_to_select=20)\n",
    "            fit = rfe.fit(features, labels)\n",
    "            selected = pd.DataFrame(rfe.support_, columns = [\"RFE\"], index=features.columns)\n",
    "            ## 3.4 Variable Importance using Extratrees Classifier \n",
    "            model = ExtraTreesClassifier(n_estimators=100)\n",
    "            model.fit(features, labels)\n",
    "            FI = pd.DataFrame(model.feature_importances_, columns = [\"Extratrees\"], index=features.columns)\n",
    "            ## 3.5 Chi Square\n",
    "            model = SelectKBest(score_func=chi2, k=5)\n",
    "            fit = model.fit(features.abs(), labels)\n",
    "            pd.options.display.float_format = '{:.2f}'.format\n",
    "            chi_sq = pd.DataFrame(fit.scores_, columns = [\"Chi_Square\"], index=features.columns)\n",
    "            ## 3.6 L1 feature selection\n",
    "            lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(features, labels)\n",
    "            model = SelectFromModel(lsvc,prefit=True)\n",
    "            l1 = pd.DataFrame(model.get_support(), columns = [\"L1\"], index=features.columns)\n",
    "            ## 3.7 Combine all methods together \n",
    "            #Selected,\n",
    "            dfs = [VI,  selected, FI, chi_sq, l1]\n",
    "            final_results = reduce(lambda left,right: pd.merge(left,right,left_index=True, right_index=True), dfs)\n",
    "            logger.debug(f\"final results \\n{final_results}\")\n",
    "            ## 3.8 Vote each variable\n",
    "            columns = ['RF', 'RFE','Extratrees', 'Chi_Square','L1']\n",
    "            score_table = pd.DataFrame(index=final_results.index)\n",
    "            for i in columns:\n",
    "                score_table[i] = final_results.index.isin(final_results.nlargest(5,i).index.tolist()).astype(int)\n",
    "            logger.debug(f\"Score_table {score_table}\")\n",
    "            score_table['RFE'] = final_results['RFE'].astype(int)\n",
    "            score_table['L1'] = final_results['L1'].astype(int)\n",
    "            score_table['final_score'] = score_table.sum(axis=1)\n",
    "            ## 3.8 Multicollinearity check using VIF - To reduce dimension\n",
    "            selected_feature_cols = score_table.nlargest(self.TOP_FEATURES_N,'final_score').index.tolist()\n",
    "            save_model(selected_feature_cols, \"selected_features.pkl\")\n",
    "            final_vars = selected_feature_cols + ['FRAUD']\n",
    "        elif self.is_train and self.check_for_retraining:\n",
    "            logger.info(\"Checking for model retraining\")\n",
    "            final_vars = saved_features + ['FRAUD']\n",
    "        else:\n",
    "            logger.info(\"Loading selected features from previous training for model scoring(prediction).\")\n",
    "            final_vars = load_model(\"selected_features.pkl\")\n",
    "            \n",
    "        logger.info(f\"Selected features are {final_vars}\")\n",
    "        self.selected_features = final_vars\n",
    "        \n",
    "    def split_data_after_feature_selection(self, selected_features, dataframe):\n",
    "        dataframe = dataframe[selected_features].fillna(0)\n",
    "        dataframe.dropna(inplace=True)\n",
    "        X = dataframe.drop(['FRAUD'], axis=1)\n",
    "        label = dataframe['FRAUD']\n",
    "        x_train, x_test, label_train, label_test = train_test_split(X, label, stratify=label, test_size=0.25)\n",
    "        return x_train, x_test, label_train, label_test\n",
    "\n",
    "    def modelling(self, x_train, x_test, y_train, y_test, metric:str=\"Sensitivity\"):\n",
    "        \"\"\"\n",
    "        Finds the best model based on the given metric.\n",
    "\n",
    "        Parameters:\n",
    "        ---\n",
    "        metric: Name of the metric based on which models will be compared. Default value is 'Sensitivity'.\n",
    "                Supported metric names are Sensitivity, Specificity, Precision, F1, ROC-AUC\n",
    "        \"\"\"\n",
    "        logger.info(\"modelling\")\n",
    "        '''\n",
    "        Prepare the data to summarize results from all classifiers\n",
    "        '''\n",
    "        model_names = ['DecisionTree','LDA','BaggingClassifier','RandomForest','ExtraTreeClassifier','XGBoostClassifier']\n",
    "        model_names = model_names[1:]\n",
    "        # define models\n",
    "        models, names,hyper_params = self.get_models(model_names)\n",
    "\n",
    "        level0_idx = ['Default', 'Optimized']\n",
    "        level1_idx = ['Model','Threshold']\n",
    "        cols = ['Train_score', 'Test_Score','Sensitivity','Specificity','Precision','F1','ROC-AUC']\n",
    "        multi_index = pd.MultiIndex.from_product([model_names,level0_idx], names=level1_idx)\n",
    "        df_score = pd.DataFrame(data='',index=multi_index,columns=cols)\n",
    "        \n",
    "        # evaluate each model\n",
    "        for i in range(len(models)):\n",
    "            # evaluate the model and store results\n",
    "            oversampling = False\n",
    "            if names[i] == \"RandomForest\":\n",
    "                oversampling = True\n",
    "            clf = self.evaluate_model(x_train, y_train, models[i], hyper_params[i], oversampling)\n",
    "            d_metric, o_metric, threshold = self.scores(clf, names[i], x_train, x_test, y_train, y_test)\n",
    "\n",
    "            df_score.loc[(names[i],'Default'),:] = d_metric\n",
    "            df_score.loc[(names[i],'Optimized'),:] = o_metric\n",
    "        # Get the best model name based on the metric. Combined model rows are ignored from the df_score.\n",
    "        if metric not in self.supported_metrics:\n",
    "            raise ValueError(f\"Currently {metric} metric is not supported for model comparison.\")\n",
    "        metric_series = df_score[metric].astype(\"float64\")\n",
    "        best_metric_index = metric_series.idxmax()\n",
    "        model_name = best_metric_index[0]\n",
    "        logger.info(f\"Scores for all the models evaluated are\\n{df_score}\")\n",
    "        return model_name\n",
    "        \n",
    "    def xgboost_model(self, x_train, x_test, y_train, y_test, metric):\n",
    "        logger.info(\"xgboost_model\")\n",
    "        '''\n",
    "        10 fold cross validation and Hyper parameter Tuning for Weighted XGBoost\n",
    "        '''\n",
    "        xg = XGBClassifier(booster='gbtree', n_jobs=-1, use_label_encoder=False)\n",
    "        xg_values = {'max_depth': [3, 4, 5, 6],\n",
    "                     'eta': [0.05, 0.1, 0.15, 0.3],\n",
    "                     'reg_lambda': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "                     'reg_alpha': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "                     'gamma': [0, 1, 2, 3],\n",
    "                     'n_estimators': [150, 250, 350, 450, 500, 550, 600, 650],\n",
    "                     'scale_pos_weight':[1, 5.08],\n",
    "                      }\n",
    "        rs_xg = RandomizedSearchCV(xg, xg_values, cv=2, n_jobs = -1, random_state=42)\n",
    "        rs_xg.fit(x_train, y_train)\n",
    "        logger.info(f\"Best parameters for xg boost are {rs_xg.best_params_}\")\n",
    "        self.best_model = rs_xg.best_estimator_\n",
    "        save_model(rs_xg.best_estimator_, \"model_best.pkl\")\n",
    "        cols = ['Train_score', 'Test_Score','Sensitivity','Specificity','Precision','F1','ROC-AUC']\n",
    "        df_score = pd.DataFrame(index=[\"Default\",\"Optimized\"], columns=cols)\n",
    "        d_metric, o_metric, threshold = self.scores(rs_xg.best_estimator_, \"XGBClassifier\", x_train, x_test, y_train, y_test)\n",
    "        df_score.loc[\"Default\",:] = d_metric\n",
    "        df_score.loc[\"Optimized\",:] = o_metric\n",
    "        logger.info(f\"Scores for XGBClassifier are\\n{df_score}\")\n",
    "        metric_series = df_score[metric].astype(\"float64\")\n",
    "        best_metric_index = metric_series.idxmax()\n",
    "        metric_value = metric_series.loc[best_metric_index]\n",
    "        # Save best models metric value which can be used for comparison during retraining.\n",
    "        save_model({\"metric\":metric, \"value\":metric_value, \"opt_threshold\": threshold}, \"best_model_metrics.pkl\")\n",
    "        '''\n",
    "        Final Model: Weighted XGBoost\n",
    "        \n",
    "        The final fitted model is the weighted XGBoost on the last 6 months dataset with no oversampling. The best estimators of the model are as follows:\n",
    "\n",
    "            Scale_pos_weight: 1,\n",
    "            Reg_lambda (L2 regularization weight): 0.01,\n",
    "            Reg_alpha (L1 regularization weight): 0.01,\n",
    "            N_estimators: 250,\n",
    "            Max_depth: 5,\n",
    "            Gamma: 2,\n",
    "            Eta: 0.15\n",
    "        '''\n",
    "        logger.info(\"Final Model: Weighted XGBoost\")\n",
    "        logger.info(f\"train score: {round(rs_xg.best_estimator_.score(x_train, y_train),3)}\")\n",
    "        logger.info(f\"test score: {round(rs_xg.best_estimator_.score(x_test, y_test),3)}\")\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        Final fitted model's performance\n",
    "        The model had a training accuracy score of 0.967 and a test accuracy of 0.844. The high accuracy score hint of a low bias (it is only a hint as accuracy is not a good measure of bias in imbalance class problems). An accuracy score difference of 0.123 between train and test is relatively small. Thus, this model can be said to have low variance and is generalizable on unseen data.\n",
    "\n",
    "            The number of cases for each class of the test set is shown in the confusion matrix below. The y-axis shows the actual classes while the x-axis shows the predicted classes.\n",
    "\n",
    "            True negative refers to non-fraud cases that are classified as non-fraud cases (161 cases, which makes up 64.40% of the test set's size).\n",
    "            True positive refers to fraud cases that are correctly classified as fraud cases (50 cases, which makes up 20.00% of the test set's size).\n",
    "            False negative are fraud cases that are classified as non-fraud cases (12 cases, which makes up 4.80% of the test set's size).\n",
    "            False positive are non-fraud cases that are classified as fraud cases (27 cases, which makes up 10.80% of the test set's size).\n",
    "            Percentage out of total sample size of the test set is printed on each quadrant.\n",
    "        '''\n",
    "        #confusion matrix\n",
    "        predictions = rs_xg.best_estimator_.predict(x_test)\n",
    "        try:\n",
    "            # P.S. get_ipython will be set in global context, when running from ipython shell or jupyter notebook.\n",
    "            # Hence it will not raise exception when run from jupyter, otherwise exception will be raised.\n",
    "            # This is done to disable plotting code when model is running from normal python shell. \n",
    "            get_ipython\n",
    "            cf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "            #labels for the inside of heatmap\n",
    "            group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "            group_counts = ['n={0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "            group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "            #put them next line\n",
    "            labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "\n",
    "            #in array 2,2 cos the heatmap will be 2,2\n",
    "            labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "            #class labeling\n",
    "            yticklabels=['Not Fraud','Fraud']\n",
    "            xticklabels=['Predicted as\\nNot Fraud','Predicted as\\nFraud']\n",
    "\n",
    "\n",
    "            # Set the default matplotlib figure size to 7x7:\n",
    "            fix, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "            # Plot the heatmap with seaborn.\n",
    "            # Assign the matplotlib axis the function returns. This will let us resize the labels.\n",
    "            sns.set()\n",
    "            ax = sns.heatmap(cf_matrix, annot=labels, \n",
    "                        xticklabels = xticklabels, yticklabels = yticklabels, \n",
    "                        fmt='', cmap='Blues')\n",
    "\n",
    "            # Resize the labels.\n",
    "            ax.set_title('Confusion matrix', fontsize=15,  fontweight='bold')\n",
    "            ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=11, ha= 'center', rotation=0 )\n",
    "            ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=11, va=\"center\", rotation=0)\n",
    "            \n",
    "            logger.info(\"Result after threshold tuning\")\n",
    "            #Section below is for threshold tuning\n",
    "            # predict probabilities\n",
    "            yhat = rs_xg.best_estimator_.predict_proba(x_test)\n",
    "            # keep probabilities for the positive outcome only\n",
    "            probs = yhat[:, 1]\n",
    "            # define thresholds\n",
    "            thresholds = np.arange(0, 1, 0.01)\n",
    "            # evaluate each threshold\n",
    "            pred_scores = [f1_score(y_test, self.to_labels(probs, t)) for t in thresholds]\n",
    "            # get best threshold\n",
    "            ix = np.argmax(pred_scores)\n",
    "\n",
    "            logger.info('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], pred_scores[ix]))\n",
    "            \n",
    "            threshold = thresholds[ix]\n",
    "\n",
    "            predicted = rs_xg.best_estimator_.predict_proba(x_test)\n",
    "            predicted[:,0] = (predicted[:,0] < threshold).astype('int')\n",
    "            predicted[:,1] = (predicted[:,1] >= threshold).astype('int')\n",
    "\n",
    "            #confusion matrix\n",
    "            #predictions = rs_xg.best_estimator_.predict(x_test)\n",
    "            cf_matrix = confusion_matrix(y_test, predicted[:,1])\n",
    "\n",
    "            #labels for the inside of heatmap\n",
    "            group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "            group_counts = ['n={0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "            group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "            #put them next line\n",
    "            labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "\n",
    "            #in array 2,2 cos the heatmap will be 2,2\n",
    "            labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "            #class labeling\n",
    "            yticklabels=['Not Fraud','Fraud']\n",
    "            xticklabels=['Predicted as\\nNot Fraud','Predicted as\\nFraud']\n",
    "\n",
    "            # Set the default matplotlib figure size to 7x7:\n",
    "            fix, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "            # Plot the heatmap with seaborn.\n",
    "            # Assign the matplotlib axis the function returns. This will let us resize the labels.\n",
    "            sns.set()\n",
    "            ax = sns.heatmap(cf_matrix, annot=labels, \n",
    "                        xticklabels = xticklabels, yticklabels = yticklabels, \n",
    "                        fmt='', cmap='Blues')\n",
    "\n",
    "            # Resize the labels.\n",
    "            ax.set_title('Confusion matrix', fontsize=15,  fontweight='bold')\n",
    "            ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=11, ha= 'center', rotation=0 )\n",
    "            ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=11, va=\"center\", rotation=0)\n",
    "        except NameError as ne:\n",
    "            # Catch the NameError generated from get_ipython\n",
    "            logger.info(\"Notebook dependant code disabled as it is not running from notebook.\")\n",
    "        logger.info(classification_report(y_test, predictions, target_names=['Not Fraud',\"Fraud\"]))\n",
    "        \n",
    "    def randomforest_model(self, x_train, x_test, y_train, y_test, metric):\n",
    "        logger.info(\"randomforest_model\")\n",
    "        rf = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "        method = SMOTE()\n",
    "        x_over_sample, y_over_sample = method.fit_resample(x_train, y_train)\n",
    "        #rf.fit(x_train, y_train)\n",
    "        rf.fit(x_over_sample, y_over_sample)\n",
    "        self.best_model = rf\n",
    "        save_model(rf, \"model_best.pkl\")\n",
    "        cols = ['Train_score', 'Test_Score','Sensitivity','Specificity','Precision','F1','ROC-AUC']\n",
    "        df_score = pd.DataFrame(index=[\"Default\",\"Optimized\"], columns=cols)\n",
    "        d_metric, o_metric, threshold = self.scores(rf, \"RandomForest\", x_train, x_test, y_train, y_test)\n",
    "        df_score.loc[\"Default\",:] = d_metric\n",
    "        df_score.loc[\"Optimized\",:] = o_metric\n",
    "        logger.info(f\"Scores for RandomForestClassifier are\\n{df_score}\")\n",
    "        metric_series = df_score[metric].astype(\"float64\")\n",
    "        best_metric_index = metric_series.idxmax()\n",
    "        metric_value = metric_series.loc[best_metric_index]\n",
    "        # Save best models metric value which can be used for comparison during retraining.\n",
    "        save_model({\"metric\":metric, \"value\":metric_value, \"opt_threshold\": threshold}, \"best_model_metrics.pkl\")\n",
    "        \n",
    "    def predict_output(self, score_df, threshold):\n",
    "        ''' Load the model from pickle file and use it for prediction.\n",
    "            Also to save time, the loaded model is saved in best_model property for future use.\n",
    "        '''\n",
    "        logger.info(\"predict_output\")\n",
    "        model_best = load_model(\"model_best.pkl\")\n",
    "        self.best_model = model_best\n",
    "        rf_probas = model_best.predict_proba(score_df)\n",
    "        logger.info(f\"Probabilities ndarray shape:{rf_probas.shape}\")\n",
    "        rf_probas_fraud = np.round(rf_probas[:,1]*100, decimals=2)\n",
    "        rf_predictions = (rf_probas_fraud > threshold).astype('int')\n",
    "        return rf_predictions, rf_probas_fraud\n",
    "    \n",
    "    def model_explainability(self, model_feature_names=None):\n",
    "        rs_xg = load_model(\"model_best.pkl\")\n",
    "        logger.info(f\"Best model {type(rs_xg)}\")\n",
    "        feature_important= None\n",
    "        if isinstance(rs_xg,XGBClassifier):\n",
    "            feature_important= rs_xg.get_booster().get_score(importance_type='weight')\n",
    "        elif isinstance(rs_xg,RandomForestClassifier):\n",
    "            feature_important= dict(zip(model_feature_names, rs_xg.feature_importances_))\n",
    "        glb_ftr_imp_df = pd.DataFrame([feature_important]).T\n",
    "        glb_ftr_imp_df.reset_index(inplace=True)\n",
    "        glb_ftr_imp_df.columns = [\"feature\", \"value\"]\n",
    "        path_glb_ftr_imp = os.path.join(self.input_dict[\"fraud_outputpath\"], self.input_dict[\"feature_importance\"], \"global_feature_importance.csv\")\n",
    "        csv_buffer = StringIO()\n",
    "        glb_ftr_imp_df.to_csv(csv_buffer, line_terminator=\"\\n\", index=False)\n",
    "        with self.fs.open(path_glb_ftr_imp, mode=\"wt\", encoding=\"utf-8\") as f:\n",
    "            f.write(csv_buffer.getvalue())\n",
    "        logger.info(f\"Global feature importance file generated at {path_glb_ftr_imp}.\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        if isinstance(rs_xg,XGBClassifier):\n",
    "            plot_importance(rs_xg, importance_type='weight', \n",
    "                            max_num_features=20, height=0.4, ax=ax, xlabel='Num of times feature used to split data across all trees',\n",
    "                        color='lightblue')\n",
    "        \n",
    "    def compare_model_by_metric(self, metric_name:str, metric_value, val_x, val_label, desired_direction:str=\"high\") -> bool:\n",
    "        \"\"\"\n",
    "        Comapre metrics given by model on new data set with metrics stored for the previous data set.\n",
    "        If metrics value deteroits w.r.t desired_direction on new data, then return True else return False.\n",
    "\n",
    "        :param metric_name\n",
    "            Name of the metric based on which comparison will be done.\n",
    "        :param metric_value\n",
    "            Metric value stored previously for the old data.        \n",
    "        :param val_x\n",
    "            New dataset on which training will be done\n",
    "        :param val_label\n",
    "            The target label of the new dataset.\n",
    "        :param desired_direction default=\"high\"\n",
    "            If set to \"high\" then higher value of metric is better, if set to \"low\" then lower value of metric\n",
    "            is better for model.\n",
    "        \"\"\"\n",
    "        pretrained_model = load_model(\"model_best.pkl\")\n",
    "        val_probas = pretrained_model.predict_proba(val_x)\n",
    "        # 1. Calculate ROC-AUC score        \n",
    "        probs = val_probas[:, 1] # keep probabilities for the positive outcome only\n",
    "        thresholds = np.arange(0, 1, 0.01) # define thresholds\n",
    "        # evaluate each threshold\n",
    "        pred_scores = [f1_score(val_label, self.to_labels(probs, t)) for t in thresholds]\n",
    "        ix = np.argmax(pred_scores)\n",
    "        logger.info('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], pred_scores[ix]))\n",
    "        threshold = thresholds[ix]\n",
    "        val_probas[:,0] = (val_probas[:,0] < threshold).astype('int')\n",
    "        val_probas[:,1] = (val_probas[:,1] >= threshold).astype('int')\n",
    "        roc_auc_score_ = roc_auc_score(val_label, val_probas[:,1])\n",
    "        # 2. Calculate sensitivity, specificity, precision and f1 score.\n",
    "        sensi, speci, preci, f1 = self.get_classification_metrics(val_label, val_probas[:,1])\n",
    "        metrics_dict = {'Sensitivity':sensi, 'Specificity':speci, 'Precision':preci, 'F1':f1, 'ROC-AUC':roc_auc_score_}\n",
    "        new_metric_value = metrics_dict.get(metric_name)\n",
    "        logger.info(f\"New metric {metric_name} value is {new_metric_value}\")\n",
    "        abs_diff = abs(metric_value - new_metric_value)\n",
    "        pct_chng = 100*abs_diff/metric_value\n",
    "        logger.info(f\"Percentage change is {pct_chng}\")\n",
    "        if metric_name not in self.supported_metrics:\n",
    "            raise ValueError(f\"Currently {metric_name} metric is not supported for model comparison.\")\n",
    "        if desired_direction == \"high\":\n",
    "            if metric_value > new_metric_value and (pct_chng > self.PCT_CHNG_ALLOWED):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        elif desired_direction == \"low\":\n",
    "            if metric_value < new_metric_value and (pct_chng > self.PCT_CHNG_ALLOWED):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    def is_retraining_required(self, metric_name, desired_direction, val_x, val_label):\n",
    "        training_required = True\n",
    "        try:\n",
    "            old_metrics = load_model(\"best_model_metrics.pkl\")\n",
    "            old_metric_name = old_metrics.get(\"metric\")\n",
    "            metric_value = old_metrics.get(\"value\")\n",
    "            logger.info(f\"Old metric {old_metric_name} value is {metric_value}\")\n",
    "            if old_metric_name != metric_name:\n",
    "                raise ValueError(f\"Old metric name {old_metric_name} doesnt match with {metric_name}.\")\n",
    "            training_required = self.compare_model_by_metric(metric_name, metric_value, val_x, val_label, desired_direction=desired_direction)\n",
    "        except FileNotFoundError as fntfe:\n",
    "            logger.error(\"Best Model metrics file not found.\", exc_info=1)\n",
    "        except Exception as e:\n",
    "            logger.error(\"Exception during check for model retraining.\", exc_info=1)\n",
    "        finally:\n",
    "            return training_required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model \n",
    "* \t\t\tThe methods `train_model(inputdata:dict)` and `get_prediction(inputdata:dict)` are mandatory and needs to be present in the `custom.py` file. \n",
    "* \t\t\tThe parameter `inputdata` in both `train_model()` and `get_prediction()` needs to be a dictionary. \n",
    "\n",
    " \t\t\tFor Example: \n",
    " `inputdata= { \"outputpath\" : \"**/output/\",  \"inputfilepath\" : \"filepath\" }`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict_train = {\n",
    "        \"file_path\" : \"/u01/HomeDir/mdesuser/POC_Data\",\n",
    "        \"raw_per_df\" : \"claimant_personal_details_actual\",\n",
    "        \"interim_df\" : \"claimant_personal_details_delta\", # This is optional,may or may not be present in location\n",
    "        \"skill_df\" : \"claimant_skill_details\",\n",
    "        \"employment_df\": \"claimant_employment\",\n",
    "        \"employer_df\": \"employers_master_details\",\n",
    "        \"Claimant_History_Personal_Details\" : \"claimant_history_personal_details\",\n",
    "        \"Claimant_History_Skill_Details\" : \"claimant_history_skill_details\",\n",
    "        \"start_date\" : \"2020-05-01\",\n",
    "        \"check_for_retraining\" : True,\n",
    "        \"comparison_metric\" : \"F1\", # Check for metric is missing\n",
    "        \"fraud_outputpath\" : \"/u01/HomeDir/mdesuser/POC_Data/MODEL_OUTPUT\",\n",
    "        \"feature_importance\": \"feature_importance\",\n",
    "        \"fraud_indicator\": \"Fraud_Indicator\",\n",
    "        \"model_feature_importance\": \"Model_Feature_Importance\",\n",
    "        \"model_output_load\": \"Model_Output_Load\",\n",
    "        \"outputpath\" : \"/u01/HomeDir/mdesuser/POC_Data\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(inputdata: Dict):\n",
    "    '''This method is used for building and training the Model.'''\n",
    "    logger.info(\"Unemployment insurance fraud model training\")\n",
    "    logger.info(f\"The input parameters for training are:\\n{inputdata}\")\n",
    "    preprocessed_data = None\n",
    "    file_system = fsspec.filesystem(\"file\") # Currently using local file system protocol\n",
    "    try:        \n",
    "        preprocess_train = Preprocessing(file_system, inputdata)\n",
    "        preprocessed_data = preprocess_train.data_preparation()\n",
    "    except Exception as e:\n",
    "        traceback.print_exc(limit=100, file=sys.stdout)\n",
    "        logger.error(\"Exception during preprocessing of data!\", exc_info=True)\n",
    "        sys.exit(\"Exception during data preprocessing during training!\")\n",
    "    # Call to python garbage collector. This call doesnt gaurenttee garbage memory will be collected.\n",
    "    gc.collect()\n",
    "    logger.info(\"Preprocessing done. Model training will start now.\")\n",
    "    model_train = None\n",
    "    try:\n",
    "        model_train = UIModel(preprocessed_data, inputdata, file_system)\n",
    "        # Limit data for last 6 months. Also drop some unnecessary columns\n",
    "        model_train.limit_records_for_training(pd.to_datetime(inputdata[\"start_date\"], format=\"%Y-%m-%d\"))\n",
    "        # transformation for ML\n",
    "        model_train.data_transformation()\n",
    "        model_train.select_model_features()\n",
    "        best_model = None\n",
    "        x_train, x_test, label_train, label_test = model_train.split_data_after_feature_selection(model_train.selected_features, model_train.df)\n",
    "        # make the check for retraining optional parameter given by user.\n",
    "        check_for_retraining_from_input = True if (inputdata.get(\"check_for_retraining\", \"true\") == \"true\") else False\n",
    "        check_for_retraining = check_for_retraining_from_input and model_train.check_for_retraining\n",
    "        # make the comparison metric an optional parameter given by user.\n",
    "        comparison_metric = inputdata.get(\"comparison_metric\",\"Sensitivity\")\n",
    "        if check_for_retraining:\n",
    "            logger.info(\"Check for model retraining on new data.\")      \n",
    "            # default desired direction is high. Meaning higher the metric value, the better is the model.\n",
    "            desired_direction = inputdata.get(\"desired_direction\", \"high\")\n",
    "            is_training_required = model_train.is_retraining_required(comparison_metric, desired_direction, x_test, label_test)\n",
    "            if is_training_required:\n",
    "                # If no exception occurred while checking for retraining and retraining is indeed needed !\n",
    "                logger.warning(f\"RETRAINING OF MODEL IS NEEDED AS METRIC ``{comparison_metric}`` IS DRIFTING.\")\n",
    "            else:\n",
    "                # If no exception occured while checking for retraining and retraining is not needed.                    \n",
    "                    # If no exception occured while checking for retraining and retraining is not needed.                    \n",
    "                # If no exception occured while checking for retraining and retraining is not needed.                    \n",
    "                logger.info(f\"PRETRAINED MODEL IS FIT FOR CURRENT DATA.\")\n",
    "                # In this case training function will stop, as retraining is not needed.\n",
    "                return\n",
    "            # elif err:\n",
    "            #     # Some error occurred while checking for retraining.\n",
    "            #     # Error may occur:\n",
    "            #     #  1) if no pretrained model is present, meaning this is the first time training is happening.\n",
    "            #     #  2) Due to some unforeseen condition not handled in `is_retraining_required` method.\n",
    "            #     logger.warning(f\"Evaluation of previous model based on metrics failed. Normal model training will start.\")\n",
    "            \n",
    "        best_model = model_train.modelling(x_train, x_test, label_train, label_test, metric=comparison_metric)\n",
    "        logger.info(f\"Best model selected after CV based on {comparison_metric} metric is {best_model}\")\n",
    "        if best_model ==\"XGBoostClassifier\":            \n",
    "            model_train.xgboost_model(x_train, x_test, label_train, label_test, comparison_metric)\n",
    "            model_train.model_explainability()\n",
    "        elif best_model==\"RandomForest\":\n",
    "            model_train.randomforest_model(x_train, x_test, label_train, label_test, comparison_metric)\n",
    "            model_train.model_explainability(model_feature_names=x_train.columns)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc(limit=100, file=sys.stdout)\n",
    "        logger.error(\"Exception during training of model!\", exc_info=True)\n",
    "        sys.exit(\"Exception during model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(input_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(inputdata: Dict):\n",
    "    '''This method is used for predicting the output when appropriate data is fed to the trained model.'''\n",
    "    logger.info(\"Unemployment insurance fraud prediction\")\n",
    "    logger.info(f\"The input parameters for prediction are:\\n{inputdata}\")\n",
    "    inputdata[\"history_data_start_date\"] = pd.to_datetime(inputdata[\"history_data_start_date\"], format=\"%Y-%m-%d\")\n",
    "    preprocessed_data = None\n",
    "    file_system = fsspec.filesystem(\"file\") # Currently using local file system protocol\n",
    "    try:\n",
    "        preprocess_scoring = Preprocessing(file_system, inputdata, training=False)\n",
    "        preprocessed_data = preprocess_scoring.data_preparation()\n",
    "    except Exception as e:\n",
    "        traceback.print_exc(limit=100, file=sys.stdout)\n",
    "        logger.error(\"Exception during preprocessing of data!\", exc_info=True)\n",
    "        sys.exit(\"Exception during data preprocessing during prediction!\")\n",
    "    logger.info(\"Preprocessing done. Model scoring will start now.\")\n",
    "    outputpath = inputdata[\"fraud_outputpath\"]\n",
    "    model_scoring = None\n",
    "    try:\n",
    "        model_scoring = UIModel(preprocessed_data, inputdata, file_system, training=False)\n",
    "        model_scoring.limit_records_for_training(pd.to_datetime(inputdata[\"start_date\"], format=\"%Y-%m-%d\"))\n",
    "        model_scoring.data_transformation()\n",
    "        model_scoring.select_model_features()\n",
    "\n",
    "        score_df = model_scoring.df[model_scoring.selected_features].fillna(0)\n",
    "        score_df_with_ids = score_df.merge(preprocessed_data[[\"CLAIMANT_ID\", \"CLAIM_APPLICATION_ID\"]], left_index=True, right_on=[\"CLAIM_APPLICATION_ID\"])        \n",
    "        best_model_metrics = load_model(\"best_model_metrics.pkl\")\n",
    "        threshold = best_model_metrics.get(\"opt_threshold\")\n",
    "        if inputdata.get(\"user_defined_threshold\", 0):\n",
    "            threshold = float(inputdata.get(\"user_defined_threshold\"))\n",
    "            threshold = round(threshold*100, 2)\n",
    "        logger.info(f\"Threshold used {threshold}\")\n",
    "        predictions, fraud_probas = model_scoring.predict_output(score_df, threshold)\n",
    "\n",
    "        score_df_with_ids[\"FRAUD\"] = predictions.tolist()\n",
    "        score_df_with_ids[\"PROBABILITY_SCORE\"] = fraud_probas.tolist()\n",
    "        fraud_map = {0:'N', 1:'Y'}\n",
    "        score_df_with_ids['FRAUD'] = score_df_with_ids['FRAUD'].apply(fraud_map.get)\n",
    "        fraud_probability_df = score_df_with_ids[[\"CLAIMANT_ID\", \"CLAIM_APPLICATION_ID\", \"FRAUD\", \"PROBABILITY_SCORE\"]]\n",
    "        fraud_probability_df = fraud_probability_df.rename(columns={\"FRAUD\":\"IS_FRAUD_REPORTED\"})\n",
    "        fraud_probability_df_path = os.path.join(outputpath, inputdata[\"model_output_load\"], \"fraud_probability.csv\")\n",
    "        csv_buffer = StringIO()\n",
    "        fraud_probability_df.to_csv(csv_buffer, line_terminator=\"\\n\", index=False)\n",
    "        with file_system.open(fraud_probability_df_path, mode=\"wt\", encoding=\"utf-8\") as f:\n",
    "            f.write(csv_buffer.getvalue())\n",
    "        logger.info(f\"Fraud probability file saved at {fraud_probability_df_path}.\")\n",
    "        # SHAP value calculation file preparation\n",
    "        temp_df = fraud_probability_df.merge(score_df_with_ids, on=['CLAIMANT_ID', 'CLAIM_APPLICATION_ID'], how='inner')\n",
    "        logger.info(f\"temp_df shape {temp_df.shape}\")\n",
    "        features_selected = model_scoring.selected_features\n",
    "        logger.info(f\"Length of features selected {len(features_selected)}\\n{features_selected}\")\n",
    "        \n",
    "        clf = model_scoring.best_model\n",
    "        # Create object that can calculate shap values\n",
    "        explainer = shap.TreeExplainer(clf)\n",
    "        # Model input file\n",
    "        shap_values = [explainer.shap_values(row[2].reshape(1,-1))[0].reshape(1,-1).flatten().tolist()+[row[0], row[1]] for row in zip(temp_df['CLAIMANT_ID'],temp_df['CLAIM_APPLICATION_ID'],temp_df[features_selected].values)]\n",
    "        logger.info(f\"Length of shap_values is {len(shap_values)}\")\n",
    "        # Create a dataframe to store shap value\n",
    "        _columns = features_selected + ['CLAIMANT_ID', 'CLAIM_APPLICATION_ID']\n",
    "        shap_df = pd.DataFrame(shap_values, columns=_columns)\n",
    "        logger.info(f\"Shap_df shape {shap_df.shape}\")\n",
    "        shap_df['CLAIMANT_ID'] = shap_df['CLAIMANT_ID'].astype(int)\n",
    "        shap_df['CLAIM_APPLICATION_ID'] = shap_df['CLAIM_APPLICATION_ID'].astype(int)\n",
    "        shap_df = shap_df.round(4)\n",
    "        logger.info(f\"shap value calculated and stored in dataframe\")\n",
    "\n",
    "        logger.info(f\"Melting the shap dataframe\")\n",
    "        melted_shap_df = pd.melt(shap_df, id_vars=[\"CLAIMANT_ID\", \"CLAIM_APPLICATION_ID\"])\n",
    "        melted_shap_df = melted_shap_df.rename(columns={\"variable\":\"FEATURE_COLS\", \"value\":\"VALUE\"})\n",
    "        melted_shap_df_path = os.path.join(outputpath, inputdata[\"model_feature_importance\"], \"model_explainability_shap_values.csv\")\n",
    "        csv_buffer = StringIO()\n",
    "        melted_shap_df.to_csv(csv_buffer, line_terminator=\"\\n\", index=False)\n",
    "        with file_system.open(melted_shap_df_path, mode=\"wt\", encoding=\"utf-8\") as f:\n",
    "            f.write(csv_buffer.getvalue())\n",
    "        logger.info(f\"shap calculated values saved at {melted_shap_df_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        traceback.print_exc(limit=100, file=sys.stdout)\n",
    "        logger.error(\"Exception during prediction using unemployment insurance model!\", exc_info=True)\n",
    "        sys.exit(\"Exception during prediction using unemployment insurance model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please save the notebook after any change to ensure the correct code extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require([\"base/js/namespace\"],function(Jupyter) {    Jupyter.notebook.save_checkpoint();    });"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please execute the following function everytime the notebook is renamed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********** PLEASE ENSURE TO EXECUTE THE BELOW SHELL BEFORE PROCEEDING FOR MODEL ONBOARDING ************ \n",
    "#### Please execute the following cell and provide the model independent and dependent variable information for creation of metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926b89014dcd4eab8d1336e61cf8325e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Textarea(value='', description='Independent:', placeholder='Comma separated inpuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b85f7771124ff1a713f3ceae51b9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Validate & Save', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3cb069ea164ab7b457446a19d4efb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enter_metadata_information(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onboard Model to CDMS \n",
    "* \t\t\tPlease execute the following cell to onboard the model to the CDMS server. \n",
    "* \t\t\tBefore onboarding the model, please ensure that the programmable interface for both training and prediction are present in the notebook and working. \n",
    "* \t\t\tPlease execution this cell will push a new version of the model to CDMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict['db_interaction'] = False\n",
    "\n",
    "onboard(metadata_dict, \n",
    "updt_db_cust_mdl=False, \n",
    "trained_mdl_type=None )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below function is provided to onboard model to remote servers. To perform the activity, please provide correct set of information for each servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rs_dict={\n",
    "    \"server_1\":{\"host\":\"\", \"username\":\"\", \"password\":\"\", \"remote_path\":\"\"},\n",
    "    #\"server_2\":{\"host\":\"\", \"username\":\"\", \"password\":\"\", \"remote_path\":\"\"}\n",
    "}  \n",
    "remote_onboarding(rs_dict)\n",
    "\n",
    "onboard(metadata_dict, \n",
    "updt_db_cust_mdl=False, \n",
    "trained_mdl_type=None, \n",
    "onboard_to_CDMS=True, \n",
    "no_of_remote_servers_to_onboard=0, \n",
    "version_increment=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
