{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='font-size:30px; color:green; font-weight: bold; margin-bottom: 20px'>Model Builder Template</div> \n",
    " \t\t\t<div style='font-size:25px; font-weight: bold'>Overview</div>\n",
    "\n",
    "* \t\t\tThis template is used for seamless integration with CDMS serving layer by preparing `custom_model.py` and `metadata.json` files.\n",
    "* \t\t\tWhen this template is opened, a folder with name same as Model Code was created in the local. \n",
    "* \t\t\tThe cells with code containing <i>import statements</i> or <i>function definitions</i> will be extracted to the `custom_model.py`.\n",
    "* \t\t\tPlease refer to the Model Onboarding User Guide to get the detailed working of this template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='font-size:20px'>Note: Rename your notebook file to some meaningful model before doing \t\t\tany model development. Changing notebook name after onboarding can make your code behave erroneously.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Informatoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Initialize metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# On branch demo_iris\r\n",
      "# Changes not staged for commit:\r\n",
      "#   (use \"git add/rm <file>...\" to update what will be committed)\r\n",
      "#   (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "#\r\n",
      "#\tmodified:   ../AutoInsurance_Fraud_Model.ipynb\r\n",
      "#\tdeleted:    ../ModelDemo.ipynb\r\n",
      "#\tdeleted:    ../ModelDemo.py\r\n",
      "#\tmodified:   ../Testing_branch.ipynb\r\n",
      "#\tmodified:   ../test.ipynb\r\n",
      "#\r\n",
      "# Untracked files:\r\n",
      "#   (use \"git add <file>...\" to include in what will be committed)\r\n",
      "#\r\n",
      "#\t../.ipynb_checkpoints/\r\n",
      "#\t../AutoFraud_Model.ipynb\r\n",
      "#\t../Iris.csv\r\n",
      "#\t./\r\n",
      "#\t../MC11/\r\n",
      "#\t../MC5/\r\n",
      "#\t../MC7/\r\n",
      "#\t../MC9/\r\n",
      "#\t../MoneyMart_PTD_Model.ipynb\r\n",
      "#\t../Untitled.ipynb\r\n",
      "#\t../ipynb_modelcode_mapper_file.pkl\r\n",
      "#\t../packages/\r\n",
      "#\t../startJupyter.sh\r\n",
      "#\t../stopJupyter.sh\r\n",
      "#\t../test.py\r\n",
      "#\t../venv_jupyter/\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: git stash list [<options>]\r\n",
      "   or: git stash show [<stash>]\r\n",
      "   or: git stash drop [-q|--quiet] [<stash>]\r\n",
      "   or: git stash ( pop | apply ) [--index] [-q|--quiet] [<stash>]\r\n",
      "   or: git stash branch <branchname> [<stash>]\r\n",
      "   or: git stash [save [--patch] [-k|--[no-]keep-index] [-q|--quiet]\r\n",
      "\t\t       [-u|--include-untracked] [-a|--all] [<message>]]\r\n",
      "   or: git stash clear\r\n"
     ]
    }
   ],
   "source": [
    "!git stash branch demo_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Meta data Information\n",
    "* \t\t\tPlease enter a unique model code, model name (e.g. Customer Churn, Propensity to Default, CLTV etc) and Model description.\n",
    "* \t\t\tPlease ensure the 'Create Workspace' button is clicked.\n",
    "* \t\t\tFor more information, please refer to the User Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enter_metadata_information(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Packages\n",
    "* \t\t\tThe following cell can be used to import all the required python packages.\n",
    "* \t\t\tPlease import the `gr` package to use the pre-defined models and functionalities. \t\t\tFor more information, please refer to the User Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import os, sys, pickle;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read Data from Source\n",
    "* \t\t\tThe following code snippet can be used to read the data from different types of sources.\n",
    "* \t\t\tPlease provide the correct details and appropriate queries to read the data. **Note**: This is optional.\n",
    "* \t\t\tThe data can also be read using the functionality provided by the `gr` package.\n",
    "* \t\t\tTo read from s3 use: df = read_data('s3://file Path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=get_data_from_db(\n",
    "dbtype='postgresql',\n",
    "username='retailuser',\n",
    "password='XXXXXXX',\n",
    "host='172.18.128.14',\n",
    "port='5533',\n",
    "database_name='APT_POC',\n",
    "sql_query='select * from <<table>>'\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(inpath):\n",
    "    return pd.read_csv(inpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis \n",
    "* \t\t\tThe following code snippet provided can be used to get first hand information on the dataset that is going to be analysed. \n",
    "* \t\t\tAfter fetching details to `pandas.dataframe df`, please execute the shell to get the data analysis report. \n",
    "* \t\t\t<div style='font-size:15px; font-weight: bold'>Warning** : This is not recommended for a huge dataset as it may take a longer time to generate the report.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_data_analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='font-size:20px; font-weight:bold'>Save Model</div> \n",
    "\n",
    "* \t\t\tThe following method can be used to save the trained model in the model folder structure created. \n",
    "* \t\t\tThe method parameter `trained_model` accepts the estimator(trained model) that is to be stored as model `pickle` file. \n",
    " \t\t\tThe method parameter `filename` accepts a `string` containing the pickle file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(trained_model, file_name):\n",
    "    model_pickle_path = None\n",
    "    try:\n",
    "        model_pickle_path = os.path.abspath(os.path.join(__file__, os.pardir, file_name))\n",
    "    except Exception:\n",
    "        model_pickle_path = os.path.join(os.path.abspath(''),file_name)\n",
    "    with open(model_pickle_path, 'wb') as pickle_out:\n",
    "        pickle.dump(trained_model, pickle_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='font-size:20px; font-weight:bold'>Load Model</div> \n",
    "\n",
    "* \t\t\tThe following method can be used to load the saved model from the model folder structure. \n",
    "* \t\t\tThe method parameter `filename` accepts a `string` containing the model pickle file name that is to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_name):\n",
    "    model = None\n",
    "    model_pickle_path = None\n",
    "    try:\n",
    "        model_pickle_path = os.path.abspath(os.path.join(__file__, os.pardir, file_name))\n",
    "    except Exception:\n",
    "        model_pickle_path = os.path.join(os.path.abspath(''),file_name)\n",
    "    with open(model_pickle_path, 'rb') as pickle_in:\n",
    "        model = pickle.load(pickle_in)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training \n",
    "* \t\t\tThe methods `train_model(inputdata:dict)` and `get_prediction(inputdata:dict)` are mandatory and needs to be present in the `custom.py` file. \n",
    "* \t\t\tThe parameter `inputdata` in both `train_model()` and `get_prediction()` needs to be a dictionary. \n",
    "\n",
    " \t\t\tFor Example: \n",
    " `inputdata= { \"outputpath\" : \"**/output/\",  \"inputfilepath\" : \"filepath\" }`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(inputdata: dict):\n",
    "    '''This method is used for building and training the Model.'''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(inputdata: dict):\n",
    "    '''This method is used for predicting the output when appropriate data is fed to the trained model.'''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Onboarding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='font-size:20px; font-weight:bold'> Please save the notebook after any change to ensure the correct code extraction.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='font-size:15px; font-weight:bold'> Please execute the following function everytime the notebook is renamed.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********** PLEASE ENSURE TO EXECUTE THE BELOW SHELL BEFORE PROCEEDING FOR MODEL ONBOARDING ************ \n",
    " \t\t\t<div style='font-size:15px; font-weight:bold'> Please execute the following cell and provide the model independent and dependent variable information for creation of metadata file.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enter_metadata_information(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Push Model to CDMS  \n",
    "* \t\t\tPlease execute the following cell to onboard the model to the CDMS server. \n",
    "* \t\t\tBefore onboarding the model, please ensure that the programmable interface for both training and prediction are present in the notebook and working. \n",
    "* \t\t\tPlease execution this cell will push a new version of the model to CDMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict['db_interaction'] = False\n",
    "onboard(metadata_dict, \n",
    "updt_db_cust_mdl=False, \n",
    "trained_mdl_type=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
